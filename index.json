[
  {
    "content": "Welcome Image by OpenClipart-Vectors from Pixabay\n",
    "description": "",
    "tags": null,
    "title": "Linux Basics",
    "uri": "/"
  },
  {
    "content": "Setting the Stage Welcome to the world of commands and the command line interface. We are going to learn a lot of commands, which may sound a lot like the incantations by witches and wizards. These commands, when combined together will create solutions that almost look magical.\nHere is a command sequence that creates a 5x5 table of numbers between 1-25\n$ echo {1..25} | xargs -n1 printf \"%02d\\n\" | xargs -n5 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 Let the journey begin ! Happy Learning MK ",
    "description": "",
    "tags": null,
    "title": "Setting the Stage",
    "uri": "/part-0/"
  },
  {
    "content": "The Basics In this part, we will discover the orgin, architecture and various flavors of the Unix operating system. We will look into concepts such File System, Permissions, IO Redirection and the commands associated with these concepts. We will create, modify and delete files and directories, view and manipulate the contents of file and much more.\nThis part will lay a strong foundation for a novice learner to become an expert command-line user.\nHere are the topics covered in this part.\n Introduction Command Syntax File System: Basics File System: Wildcards Permissions IO Redirection Viewing Files Data Manipulation Running Multiple Commands  ",
    "description": "",
    "tags": null,
    "title": "Getting Started",
    "uri": "/part-1/"
  },
  {
    "content": "Text Processing Part: II Topics  Regular Expression The Vi Editior grep command: search and filter text sed command: The Stream Editor awk command: programming language as a command  ",
    "description": "",
    "tags": null,
    "title": "Text Processing",
    "uri": "/part-2/"
  },
  {
    "content": "Beyond the Basics Part: III Topics  Process Management Scheduling Jobs Network Commands Archival Commands Advanced Commands: find Advanced Commands: xargs  ",
    "description": "",
    "tags": null,
    "title": "Beyond the Basics",
    "uri": "/part-3/"
  },
  {
    "content": "Shell Scripting Part: IV Topics ",
    "description": "",
    "tags": null,
    "title": "Shell Scripting",
    "uri": "/part-4/"
  },
  {
    "content": "Appendix Contents A. Command List\n",
    "description": "",
    "tags": null,
    "title": "Appendix",
    "uri": "/part-5/"
  },
  {
    "content": "Chapter 1 Warning This topic is still in progress Please check later…\n Introduction The world is full of computing devices. We interact with these devices using the mouse, keyboard and more predominantly using touchscreens and voice assistants. Though these type of interactions are user-friendly and intuitive, these options do have limitations and often proved to be slow and error-prone to perform repetitive tasks. There is another way, a much better way to interact with the systems; by using the keyboard to type commands and get the work done. This way help us to become more productive and automate the repetitive tasks easily.\nArchitecture ",
    "description": "",
    "tags": null,
    "title": "1.1: Introduction",
    "uri": "/part-1/p1-ch1/"
  },
  {
    "content": "Chapter X Regular Expressions (RegEX) Warning This topic is Yet to start…\n ",
    "description": "",
    "tags": null,
    "title": "2.1: Regular Expressions",
    "uri": "/part-2/p2-ch1/"
  },
  {
    "content": "Chapter X Warning This topic is Yet to start…\n ",
    "description": "",
    "tags": null,
    "title": "3.1: Process Management",
    "uri": "/part-3/p3-ch1/"
  },
  {
    "content": "Chapter X Warning This topic is Yet to start…\n ",
    "description": "",
    "tags": null,
    "title": "4.1: Introduction to Shell Scripts",
    "uri": "/part-4/p4-ch1/"
  },
  {
    "content": "Unix and Linux  Ken Thompson for the wonderful operating system Dennis Ritchie for the C language Linus Torvalds for Linux Douglas McIlroy for the concept of pipes and for the sort, join and other useful commands   Tools and Utilities  Steve Francia for the Hugo Static Site Generator @McShelby for the Relearn Theme Pixabay for the stunning free images  ",
    "description": "",
    "tags": null,
    "title": "Acknowledgement",
    "uri": "/part-0/p0-ch1/"
  },
  {
    "content": "Chapter 2 Overview Commands are the backbone of the Linux operating system. There are thousands of commands in different categories and remembering all the commands in impossible. What we really need is to understand the syntax of the command well and the components that make up a command string.In this chapter, we will look into the command syntax, the components that make up various commands that we use on a daily basis. Understanding the structure of the command makes learning and using new commands easier.\nThe Unix Philosophy is all about simplicity and reusability. The commands are there to do only one thing and do it really well. There are features like redirection that helps us use multiple commands together to solve complex problems however the commands themselves focus on providing solution for a single problem.\n Some commands appear before we cover them in detail. These commands serve as supplement to demonstrate other commands. For example the ls command that is used to list files and directories. We will see these commands in detail at the later sections\n Let us look at couple of examples first\nThe echo command can be used to display text on the screen. The command accepts sequence of characters as argument and display it on the screen.\n$ echo \"Hello World\" Hello Word The date command displays current date and time on the screen. We can modify the default format by passing date format string as argument\n# date: default format $ date Fri Jul 2 15:05:19 IST 2021 # date: display date in YYYY-MM-DD format $ date +\"%Y-%m-%d\" 2021-07-02 What is a command ? A command contains one or more words that are separated by spaces, which will be executed when we press the enter/return key . The first word is the verb that refers the action followed by zero or more words that are called options or argumets. The basic syntax of a command is as follows\n$ command [option(s)] [argument(s)]  We usually code options after the command followed by the arguments.\n Arguments Arguments are entities (usually files, text or numbers) that the command will act on. Lot of commands have default argument. For example, the ls command that is used to list files and directories accepts a directory path as argument. If we don’t provide one, it will take the current working directory as the default argument.\nOptions Option, also called as flag can modify the behavior of the command. For example, most of the commands will not display any message when they get executed successfully. We use option to turn on the verbosity of the command.\nOptions can have their own arguments too. For example: the awk command’s option -F, uses , as an argument (field delimiter) and grep command’s --color=always uses always to highlight searched text.\nOptions are coded with a leading - or --. The ones with - are usually followed by a single character; -v for example and the ones with -- are followed by multiple characters; --verbose for example.\n The find command is an exception to the way - and -- are used. Its options use - followed by a word; -type, -user, -atime for example\n We can merge multiple single character options and code with one leading -; for example mkdir -p -v data/input or mkdir -pv data/input.\nEach command supports set of options and usually there can be both - and -- versions. We can use the - version for our day-to-day use on the shell whereas the -- can be used in the shell scripts that works as a self-documentation. For example, the mkdir command that creates directories can use -v or --verbose to, you guessed it right, turn on the verbosity of the command.\n verbosity: the quality of using more words than needed; ..just like this article.\n Since several people contributed to the development of UNIX, there are cases where an option has different meaning for different commands. For example -v means verbose mostly, it also means version for some commands and inverse match in the grep command. On the other hand, same functionality would use different option across commands. For example, -d, -t, -s and -F are used to provide field separators to the cut, sort, column and awk commands respectively\nFinally, since - has a special meaning, if we want to use - as a part of argument, we need to simply code -- to mark the end of the options.\nTo summarize, Options\n are also called as flags that can modify the behavior of the command start with a - or -- prefix single - prefix is followed by a single character and we can code multiple options with one leading - or individually; -pv or -p and -v double -- prefix is followed by a multi-character option name; --verbose, --all, … standalone -- signals end of options and whatever is passed after the -- will be treated as argument same option may mean different functionality across commands same functionality may be represented by different options across commands  Basic Commands This section covers the basic commands that we will encounter when we start learning the command line interface. These commands are there to get information about the system such as current date, current working directory, clear screen etc..\n These commands gives us a good start to get ourselves comfortable using the shell / CLI\n    # Name Description     1 echo \u003cSTR\u003e print the string on the screen   2 pwd print current working directory   3 date print current date and time   4 clear clear the screen, use the CTRL-L key as alternate   5 sleep \u003cN\u003e sleeps for N seconds   6 cal displays current month’s calendar in tabular format.   7 man CMD displays help text for the CMD passed as argument.   8 history display the list of commands ran so far   9 passwd change password   10 seq create number sequence   11 exit terminate session    1. echo STR: displays text on screen By default, the echo command simply displays the argument on the screen. If we provide a shell variable, it will substitute the value instead.\n   Option Description     -n suppresses newline   -e interprets escape sequences like \\n, \\t` etc    # displays text and adds newline $ echo \"Hello World Hello World $# displays a new line if there are no arguments $echo $# displays text; '-n' suppresses new line $echo -n \"Hello World Hello World$ # interprets tab and newline $ echo -n -e \"Hello\\tWorld\\n\" Hello World $ # display value of $USER: shell variable $ echo \"Hello, $USER\" Hello, mk 2. pwd : print working directory pwd is one of the simplest commands we will encounter in Linux. It simply displays current directory you are in. When you are in the shell, you will be in your home directory\n$ pwd /home/mk 3. date : Set / Display Current Date and Time By default, it prints the date in ddd, dd mmm yyyy HH:MM:SS. AM|PM TZ format. If we have admin access, we can set the date and time. Here is the basic syntax.\n$ date +\"format string\" We can use format strings to print date in several formats\n   Format String Meaning Value(s)     %d Current Date 01-31   %m Current Month 01-12   %y Current Year 2 digits 00-99   %Y Current Year 4 digits 1999, 2020 etc..   %H Hour 00-23   %M Minutes 00-59   %S Seconds 00-59   %s Seconds since 1-Jan-1979 seconds as integer    For complete reference, please refer the manual pages for the date command; man date\n$ date Sat 03 Jul 2021 03:59:27 PM UTC $ date +\"%Y%m%d\" 20210703 $ date +\"%Y%m%d%H%M%S\" 20210703155949 $ date +\"%Y-%m-%d\" 2021-07-03 $ date +\"%F\" 2021-07-03 4. clear : Clears the Screen !! The clear command cleans out the display and put the command prompt $ on the first line of the terminal. Based on the terminal settings, you may or may not scroll back. In some emulators, clear may not work. We can use Control key + l CTRL-L to clear out the screen\n5. sleep N : sleep for N seconds The sleep command blocks the terminal for N seconds and return the command prompt back to the user. It can be used in wait and watch scenarios. For example, wait for 5 seconds and lookup a file in a directory. While learning, we can use sleep to simulate the effect of a long running command.\n We can run commands one by one or submit the commands at the same time using semicolon ; as delimiter\n $ date;echo \"Start Sleep\";sleep 5; date Sat 03 Jul 2021 04:09:44 PM UTC Start Sleep Sat 03 Jul 2021 04:09:49 PM UTC 6. cal : displays calendar The cal command displays days of current month in tabular format with current date highlighted. We can pass month and year or year as argument.\n$ cal July 2021 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 $ cal dec 2020 December 2020 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 7. man CMD : display manual pages for a command The man command is used to access the manual pages for commands and system calls. It displays one screenful of documentation at a time and we can use the following sub-commands to navigate the man pages.\n f or spacebar : go to the next page b : go to previous page enter key or down arrow : scroll next line up arrow : scroll previous line q : quit man page  8. history : displays command history Linux keeps track of the commands executed across various login sessions. By default, it will store the last 500 commands. We can use the history command to list the previously executed commands along with the line number. There are some shell expansions to rerun or just print any of these commands.\n$ history 1 echo \"Hello World\" 2 date 3 pwd 4 clear 5 cal ... We can rerun the last command by using !! characters. If we use !!:p, shell just prints the last command instead of running it\n$ date Sat 03 Jul 2021 04:37:37 PM UTC $ !! date Sat 03 Jul 2021 04:37:39 PM UTC The !N can be used to execute the Nth command in the history and !N:p prints the Nth command instead of running it\n$ !10 date Sat 03 Jul 2021 04:40:10 PM UTC $ !10:p date there is more to history expansion, we shall look into that later\n9. passwd : change password The passwd command is used to change the existing password. This command is useful to proactively change the password in a multi-user server that has password expiry policy. The command will prompt for the current password. If correct password is provided, it will ask for new password and once reenter the new password again, it will change the password\n$ passwd Changing password for mk. Current password: New Password: Retype Password: passwd: password updated successfully. 10. seq : print number sequence The seq command can be used to generate number sequence. It requires one numeric argument as stop value and it generates numbers between 1 and stop value by increment of one. We can also provide start and step values. The number can be integers or decimals\n one argument: stop value; start and step == 1 two arguments: start, stop values; step == 1 three arguments: start, step, stop values  The -w option pads smaller numbers with leading zeros and -f \"FORMAT STR\" can be used format numbers like printf\n# start at 1 (default), increment by 1 (default), stop at 5 $ seq 4 1 2 3 4 # start at 2, increment by 1 (default), stop at 5 $ seq 2 4 2 3 4 # start at 2, increment by 2, stop at 5 $ seq 2 2 5 2 4 11. exit : exit current process The exit command terminates the current process. If it is entered in the command prompt, it will terminate the session. We can also use the logout command\nExtras: Why use - and -- as option prefix\nAs far as I understood, the earlier commands had - with single-character options first and since multiple - options can be combined together (-p, -v vs -pv), the developers might have needed a different syntax for multi-character options and used -- for that. For example, the ls command has --all option to include hidden files in the output, if we code -all then ls will take it as -a, -l and -l. Confusing ?? Try ls -all and ls --all\n",
    "description": "",
    "tags": null,
    "title": "1.2: Command Syntax",
    "uri": "/part-1/p1-ch2/"
  },
  {
    "content": "Chapter X Vi Editor Getting Started Warning This topic is still in progress…\n Open a new file\n$ vim Press i to enter insert mode and start typing. Once done, press ESC to go to normal mode to save and continue editing or exit.\nsave the new file\n:w FILE save and exit\n:wq FILE  Open a new file with a name or existing file\n$ vim sample.txt Press i for insert and ESC to exit insert mode and\n# save file :w # save and exit :wq Cursor Movement    Command Description     h move one character left   j move one character down   k move one character up   l move one character right   0 move one column one of current line   ^ move to the first non-blank character of the current line   $ move to the end of the line   gg move to the first line   G move to the last line   \u003cn\u003eG move to line \u003cn\u003e    Cursor Movement by Word    Command Description     w move to the next word; separated by a non-word character [^0-9A-Za-z_]   W move to the next word; separated by blank characters [^ \\t\\r\\n\\v\\f]   e move forward to the end of the word; separated by a non-word character [^0-9A-Za-z_]   E move forward to the end of the word; separated by blank characters [^ \\t\\r\\n\\v\\f]   b move to the previous word; separated by a non-word character [^0-9A-Za-z_]   B move to the previous word; separated by blank characters [^ \\t\\r\\n\\v\\f]    Cursor Movement in the Current Window    Command Description     H move to the first line of the current window   M move to the middle line of the current window   L move to the last line of the current window    Cursor Movement: Page up/down (scrolling)    Command Description     ^F go to next page (Forward)   ^B go to previous page (Back)   ^U go to previous half page (Up)   ^D go to next half page (Down)    Getting into Insert Mode    Command Description     i insert text at the cursor   I insert text at the beginning of the line; same as ^i   a append text after the cursor   A append text at the end of the line; same as $a   o open a line after current line for imsert   O open a line before current line for imsert    Cut/Delete, Copy and Paste When we issue a cut / copy / delete, we need to specify what is that we are copying or deleting; as in are we doing this operation on a character, line, word, few lines etc…\nThese commands are always accompanied by a cursor movement command. Example w, G, $ etc..\n   Command Description     d\u003cC\u003e cut / delete followed by cursor command   y\u003cC\u003e copy followed by cursor command; y means yank   p paste after cursor   P paste before cursor    Let us say we use X as subsititue for d or y. Here are some examples\n   Command Description     XG from current position to end of file   Xw cut/copy the current word   X5w cut/copy the 5 words from current position   X$ cut/copy from current position till end of the line    Search and Replace    Command Description     f\u003cCH\u003e find forward a character CH on the current line   F\u003cCH\u003e find backward a character CH on the current line   t\u003cCH\u003e like f\u003cCH\u003e but the cursor will be one char before the `   T\u003cCH\u003e like t\u003cCH\u003e but the cursor will be one char after the `    ",
    "description": "",
    "tags": null,
    "title": "2.2: Vi Editor",
    "uri": "/part-2/p2-ch2/"
  },
  {
    "content": "Chapter X Warning This topic is Yet to start…\n ",
    "description": "",
    "tags": null,
    "title": "3.2: Scheduling Jobs",
    "uri": "/part-3/p3-ch2/"
  },
  {
    "content": "Chapter 3 Warning This topic is still in progress Please check later…\n Introduction File System is one of the core components of any operating system. It provides a well-defined structure to store, organize and retrieve content and the metadata associated with the file such as owner, permissions, size, timestamps etc.. Each operating system has its own File System definition, for example Windows uses NTFS and Mac uses APFS. Both Windows and Mac supports old FAT32 file system.\n A File can be informally defined as the collection of records and fields also known as data that are stored as stream of bytes. It is the smallest logical unit of storage in the OS.\n  A directory is a container to store other directories and files. It is a special type of file that contains the references to itself, the parent and other files and directories stored in it.\n Unix and Unix-like OS use the HFS - Hierarchical File System. Though each Unix-like OS may have a unique name for the file system such as JFS, ext3, ext4, these are simple the implementations of the HFS - the original file system of the Unix operating system. Each of these file system may have extended attributes such as maximum size limits per each file and the file system itself.\nIn this chapter, let us discuss the following topics\n The features of the file system, how files are organized and the metadata stored along with the contents Path: textual representation that uniquely identifies file or a directory Wildcards: patterns to access one or more files Commands: create, access, delete, list files and directories  HFS: Hierarchical File System Unix treats everything as files; data, source code, executables, even devices such as display, hard disks. The HFS provides a standard way to store and access these files. As the name suggests, Hierarchical FS is a tree-like structure that has nested directories and files. A directory that resides within another directory is called a sub-directory.\nThe HFS has single entry point called the root directory. It is represented by the backslash / not the name root. This is an important distinction to remember. Every file and directory in the system is nested under the root directory, even when you attach devices such as USB, these devices will show up under the root directory. This is another difference between Windows and Unix OS. In Windows, each device will show up as independent drives E:, G: etc..\nImages by Gerd Altmannfrom Pixabay and mcmurryjulie from Pixabay\nHere is the graphical representation of the common directories and files we would see under the root directory.\nThe above illustration is not all inclusive but a snapshot of the common directories and files we will see in Unix-like systems. These directories contain commands, config files and other info needed for the proper functioning of the system.\n bin : contains commonly used commands such as echo, ls; bin is the short form for binaries sbin : system binaries that are mostly used by sysadmins dev : contains device specific files; tty* for displays, sda* for hard-drives and other logical devices like /dev/null and /dev/urandom etc : contains system configuration files. For example /etc/shells contains list of available shells tmp : store temporary files that are periodically cleaned up. usr : contains commands that are installed separately, non-core commands, interpreters etc… home : contains one directory per user that can logon to the system. /home/admin, /home/dbuser etc.. lib : contains system libraries var : contains growing files such as logs, databases. Most of the directories under the root directory won’t grow drastically in size except the var and home directories  Path In the chapter about command syntax, we saw that files and directories can be passed as arguments to commands. In order to access the files, we need an unique way of identifying the files. The path is a textual representation that can uniquely identify any file or directory in the system.\nThere are two ways we can represent the file path.\n Absolute Path Relative Path  Absolute Path As the name suggests, an absolute path is a representation that will never change for a given file. It starts with the root directory followed by the sub-directory names and that may end with a file or directory name. The sub-directories are delimited by the path separator /\n The character / has two roles; when it appears at the start of the path, it represents the root directory and when it appears in between, it is called the path separator.\n The absolute path name always starts with a / that represents the root directory. For example /usr/bin/awk is the absolute path of the awk command.\nAbsolute Path Examples\n /home/dbuser/bin/list_old_files.sh : a shell script inside the home directory of an user called dbuser /etc/shells : a system config file that contains the list of available shells /tmp/tmp.knD5sAulSZ : an ephemeral file created by some process that will be cleaned up once the process is completed or by the operating system  Relative Path Unlike the absolute path that is always same for any given file, the relative path will not be the same. The value of relative path of a given file is determined based on the current working directory the user is in or the command is running from.\n REMINDER: The user will be placed in the home directory of the user upon login and the user is always at one directory or another during the login sessions in order to interact with the system.\n We can use some short-hand notations in the table given below to construct the relative path.\n   Symbol Description     / the path separator, that delimits directories in the path   . reference to the current directory, can be used as a shortcut   .. reference to the parent directory   ~ shortcut to the home directory of the current user   ~admin shortcut the home directory of the user called admin    Relative Path Examples\n data/input/sample.txt : refers to the file sample.txt that is inside input which again is inside data directory of the current directory (pwd) ../../data : go two level up from the current directory and access the data directory ~/bin/main.sh : refers main.sh that is inside the bin directory of the current user’s home directory. This is not exactly a relative path, this one uses one of the path’s shortcut available that is ~ (home directory of the current user) ~dbuser/bin : refers the bin that is under the home directory of user dbuser  Absolute vs Relative Paths Using the below tree structure3, let us see few examples of absolute and relative paths of few files and directories listed here.\nLet us say the current location of the user in the shell is /home/admin. The result we get when we run the pwd command. For the sake of demo, we have kept all directory and file names unique.\n   To access Absolute Path Relative Path     bin /home/admin/bin bin     ~/bin   in /home/admin/data/in data/in     ~/data/in   mysqld.log /home/dba/log/mysqld.log ../dba/log/mysqld.log     ~dba/log/mysqld.log   proj /proj ../../proj   scores.dat /home/admin/data/out/scores.dat data/out/scores.dat    Both type of path’s have their own pros and cons. Here is a brief summary\n   Absolute Path Relative Path     Starts with the root directory / starts with a directory name or some shortcuts like .., .. never starts with the / that is the root directory   Always remains the same Changes based on the current directory   no ambiguity works best in environments that follows standard directory structure   may be longer may be shorter than the corresponding absolute path    File System Commands: Part I  This section covers commands that are used to create files and perform operations on these files, such as access, copy, move, delete etc.. Here is the list of commands we will deal with examples\n In this chapter, we will look at a set of File System commands and in the following chapter, we will discuss wildcards and another set of commands\n    # Name Description     1 mkdir create directory   2 cd change directory   3 rmdir remove empty directories only   4 touch create an empty file if it doesn’t exists   5 file determine file type   6 ln create link to an existing file; hard or soft link   7 tree list a directory contents in a tree like format    mkdir : create directories The mkdir (make directory) command accepts a path as an argument and creates the innermost directory name in the path by default. It errors out if the directory already exists or if some intermediate directories in the path does not exist already.\nCommonly used options\n   Option Description     -v enable verbose mode.    displays a message when the directory is created successfully.    Same as --verbose   -p creates intermediate directories in the path, if not exist.    Same as --parents   -m MODE override default permission using an octal string. More on this later.    Create one or more directories\n# display current directory $ pwd /home/mbose/demos/hfs/dir # list files and directories at cwd $ ls # mkdir: no flags, creates directory, no messages $ mkdir $ ls data # option: -v or --verbose - display dir creation message $ mkdir -v data/input mkdir: created directory 'data/input' $ ls data input # mkdir: create multiple dirs at same level $ mkdir -v bin etc log mkdir: created directory 'bin' mkdir: created directory 'etc' mkdir: created directory 'log' MK@gshell dir $ ls bin data etc log Create parent directories as needed\n# mkdir: errors out if sub-directories do not exist $ mkdir config/db mkdir: cannot create directory ‘config/db’: No such file or directory # option: -p or --parents: creates sub-directories as needed  $ mkdir --parents --verbose config/db mkdir: created directory 'config' mkdir: created directory 'config/db' cd : change directory When an user logs in, the first default directory (s)he will be places is the user’s home directory /home/userid. In order to work in the shell, the user has to move from one directory to another frequently. The cd command is used to change user’s current directory.\nThe cd command accepts one argument that is a path (relative or absolute) of a directory. If no arguments are provided, then cd uses the current user’s home directory as default argument.\nNote: The - has a special meaning for cd. It will substitute the previous working directory and executing the cd - command will take the user back to the previous working directory. Executing cd - consecutively mimics the Alt + Tab like operation of Windows environment. The cd - will display the directory name it is going to switch\n cd errors out if the directory provided as argument does not exists or it exists but it is not a file. If the user does not have permission to access a valid directory, it would cause an error\n $ pwd /home/mbose/trainings/demos/hfs/dir # cd: defaults to user's home dir $ cd $ pwd /home/mbose # cd: with argument $ cd data/input $ pwd /home/mbose/demos/hfs/dir/data/input # cd - : changes back to previous working directory $ cd - /home/mbose/trainings/demos/hfs/dir $ pwd /home/mbose/trainings/demos/hfs/dir Errors:\n$ ls bin config data etc log sample.txt # cd: directory does not exist $ cd temp -bash: cd: temp: No such file or directory # cd: not a directory $ cd sample.txt -bash: cd: sample.txt: Not a directory # cd: inadequate permission $ cd etc/ -bash: cd: etc/: Permission denied rmdir : remove “empty” directories ONLY The rmdir command is used to delete directories that are empty. It accepts If there are files or other directories then we need to use the rm command that will be discussed later in this chapter.\nThe rmdir also supports the -p and -v; parents and verbose options like the mkdir command. The -p option takes a path and deletes the innermost directory first and traverse back and delete as long as the current directory it is trying to delete is empty\nExamples: Delete empty directories\n$ ls bin config data etc log # rmdir: no option, silently deletes dir, if empty $ rmdir bin $ ls config data etc log # rmdir -v: display a message about the dir being deleted $ rmdir -v etc rmdir: removing directory, 'etc' $ ls config data log # we can delete multiple directories at the same time $ mkdir temp $ ls config data log temp $ rmdir -v temp log rmdir: removing directory, 'temp' rmdir: removing directory, 'log' $ ls config data Errors:\n# invalid dir: not exists $ rmdir backup rmdir: failed to remove 'backup': No such file or directory # argument is a file $ rmdir sample.txt rmdir: failed to remove 'sample.txt': Not a directory # insufficient permission; created by root user $ rmdir etc rmdir: failed to remove 'etc': Operation not permitted touch : create empty files The touch command can be used to create an empty file, if it does not exists. It changes the file’s access and modification timestamps, if the file exists. This command is an useful utility for beginners to create files and play around with commands, at the same time it is powerful enough to be used to trigger events by changing the access / modified timestamps. The files with updated timestamps will be picked up by file listener events and services\n If a file name starts with a dot ., it will not be visible automatically when we list files. These files are called hidden files or dotfiles and these need special options to be displayed\n |Options|Description| | -a | change only the access time, do not change modified time | | -a | change only the modified time, do not change access time | | -d | uses the argument instead of current time; --data=STRING | | -t | accepts a timestamp and use it as current time|\n We will do a demo on -d and -t along with the ls command\n $ ls config data $ touch sample.txt sample.csv $ ls config data sample.csv sample.txt file : determine file type The file command accepts a file as an argument and tries to determine the type of file by looking at various features like known file extensions, checking file stats for emptiness, character checks for ASCII or binary format etc.. The command prints the type of the first passed test. If it cannot determine anything, it simple prints data\nCreate sample files and directories for demo\n$ mkdir temp $ file temp temp: directory $ touch sample.txt $ file sample.txt sample.txt: empty # an existing text file $ file /etc/shells /etc/shells: ASCII text # an executable $ file /usr/bin/perl /usr/bin/perl: ELF 64-bit LSB pie executable, x86-64, version 1 # compressed zip file $ file backup.zip backup.zip: Zip archive data, at least v1.0 to extract # compressed gzip file $ file tarball.tgz tarball.tgz: gzip compressed data, last modified: Fri Jul 9 13:44:48 2021, from Unix, original size 10240 # contains random ascii char from /dev/urandom  $ file random.bin random.bin: data ln : create links or shortcuts The ln command is used to create shortcut to an existing file or directory. There are two type of links we can create; hard links and soft or symbolic links\nA hard link is an additional name for an existing file. If the original file is deleted, we can still access the data using the hard link. We cannot create hard links for directories. Both files will be pointing to the same inode, an unique number assigned to each file created in the system.\nA soft link like the shortcut in the Windows environment. We can create a soft or symbolic link for both files and directories. If the original file is deleted, the symbolic link will remain broken and accessing that link will cause error\nLinks are useful in many ways; we can create a short name as symbolic link to frequently used files and directories. For applications, that need to access the latest file from a given set of files with the date in it, the process that creates these files can create a symbolic link and the application can use the link instead of the actual latest file.\n   Options Description     -v enable verbose mode   -s create symbolic link, hard link will be created by default   -t DIR directory name on which the link should be created    $ ls config date regular files touch weblog_20210705.log weblog_20210706.log # create symbolic link ln -s weblog_20210706.log weblog.log $ file weblog.log weblog.log: symbolic link to weblog_20210706.log # create hard link: both original and link has same inode $ ln weblog_20210705.log weblog # ls -1i : displays file and its inode, one per line # **Note**: both files have same inode 133719 $ ls -1i weblog weblog_20210706.log 133719 weblog 133719 weblog_20210706.log tree : display contents of directory recursively The tree command displays all the sub-directories and files under the current directory (default). We can explicitly pass a directory as argument\n   Options Description     -a print all files, including hidden files   -d print directories only, discard files   -L N print only N sub-levels of nested directories   -f display full relative path for each file and directory   -o FILE send output to FILE instead of screen     The tree command is not installed by default in many OS (google cloud shell) or emulators like cygwin.\n Create sample files and directories\n$ mkdir tree_demo $ cd tree_demo $ mkdir -p processor/intel/i3/{bin,data,etc,log} $ mkdir -p processor/intel/i3/data/{in,out}put $ touch processor/intel/i3/log/cycled.log $ touch processor/intel/i3/data/run_1a.dat $ touch processor/intel/i3/data/input/source.dat $ touch processor/intel/i3/data/output/{xa,xb,xc}.dat $ touch processor/intel/i3/bin/.config tree demo\n$ tree . └── processor └── intel └── i3 ├── bin │ └── main.sh ├── data │ ├── input │ │ └── source.dat │ ├── output │ │ ├── xa.dat │ │ ├── xb.dat │ │ └── xc.dat │ └── run_1a.dat ├── etc └── log └── cycled.log Display directories only, discard files\n$ tree -d . └── processor └── intel └── i3 ├── bin ├── data │ ├── input │ └── output ├── etc └── log Limit levels of sub-directories\n$ tree -d -L 3 . └── processor └── intel └── i3 Display Hidden Files\n# display hidden file .config $ tree -a processor/intel/i3/bin processor/intel/i3/bin ├── .config └── main.sh Save output in file instead of display on screen\n$ tree -d -L 3 -o tree.out # display file using `cat` command $ cat tree.out . └── processor └── intel └── i3 …to be continued in part 2\n",
    "description": "",
    "tags": null,
    "title": "1.3: File System: Basics",
    "uri": "/part-1/p1-ch3a/"
  },
  {
    "content": "Chapter 4 Warning This topic is still in progress Please check later…\n Introduction In the previous chapter, File System: Basics, we have discussed the importance of file system and its use in storing, retrieving files and the metadata. We have also discussed about absolute and relative paths, the way to access files stored in the system and the first set of commands to create files, directories and links (shortcuts) and commands to list files and directories and get information about different type of files.\nIn this chapter, we will look into wildcards, a feature provided by shell to create patterns to match file and directories and more commands to perform operations such as copy, move, rename and delete files and directories, list contents of files and directories, get file usage statics and display used and free space of the disks attached to the system.\nPoints to remember  Linux treats everything that is stored in the system as file A directory is a special type of file that has references to other files and directories stored in it File names that start with a . are called hidden files and we need options to display these files The file system has a single entry point / aka the root directory There are two type of path names to refer files and directories; absolute and relative paths Most of the commands are silent when executed successfully. We need to enable the verbose option -v or --verbose to get message about the activity  Wildcards Wildcards are the shell feature that allows us to create patterns that can be used as argument in place where files or directories are expected. The pattern may match zero or more files thus helping us reduce the typing and avoid mistakes\n   Wildcard Description     * represents zero or more characters   ? represent any one character   [abc] any one of the listed characters   [^abc] any one ASCII character other than the listed characters   [!abc] same as [^abc]   [a-z] any one of the lowercase alphabet; - represents range   [^a-z] any one character other than the lowercase alphabet   [!a-z] same as [^a-z]   [[class]] matches a group of characters referred by the class name    Common character groups: [[class]]\n The class name is a placeholder for a single character from the character set\n |Class|Description| |[:alpha:] |upper and lowercase alphabet| |[:lower:] |lowercase alphabet| |[:upper:] |uppercase alphabet| |[:digit:] |numbers: 0-9| |[:xdigit:] |hexadecimal numbers: 0-9A-Fa-f| |[:alnum:] |alphabets and numbers 0-9A-Za-z| |[:space:] |space, tab, newline, carriage return and vertical tab|\nWildcard Examples:\n *.txt : any file that ends with .txt that has Zero or more characters prefix; .txt, a.txt, sample_file.txt,… a?.txt : any file that starts with an a followed by only one character and ends with .txt; a1.txt, az.txt, a@.txt,… [aeiou][0-9].txt : any file that starts with a lowercase vowel followed by a number; a1.txt, z9.txt, … [aeiou][^has 0-9].txt : any file that starts with a lowercase vowel followed by a non-number character; aX.txt, zZ.txt, … [[:xdigit:]][:xdigit:]][[:digit:]]: files that are three character long, first 2 chars are hexadecimal digits 0-9A-Fa-f and one number 0-9; ff9, ef3, bc4  Brace Expansion: {...} There is another special character set called the brace expansion that is used as wildcard. This is not used to create patterns to match existing files and directories, instead it can be used to generate combination of text patterns.\n   Type Description     A{op1,op2,op3}Z creates 3 strings with prefix + {each option} + suffix   {1..10} generates number between 1-10, both inclusive   {01..100} generated 001 002 003 ... 100 in latest BASH versions;     if brace expansion is used in commands that expects actual files and directories as arguments, the commands will produce file not found error for text generated that are not the name of existing files; rmdir command for example\n Brace Expansion Examples:\n echo sample.{csv,txt,dat} will display sample.txt, sample.csv and sample.dat touch sample.{csv,txt,dat} will create there empty files named sample.txt, sample.csv and sample.dat echo {a,x,z}{1..3} will display a1 a2 a3 x1 x2 x3 z1 z2 z3 mkdir -pv 20{20,21}/{01..12}/{01..31} creates nested directories; 2020 and 2021 as top-level directories and each directory contains 12 directories for months 01-12 and each month has 31 directories for days 01-31. This command creates around 750+ directories in one go   if the Bash version is less than 4.x echo $BASH_VERSION then the month and date may not have leading zeroes for values 1-9\n Escaping and Quoting Since the shell has special meanings for certain characters such as the ones used in wildcards, we need a mechanism to pass these characters as-is without special meanings. We need a way to decide when to use these characters to represent the special meanings and when to use as-it-is. There are two ways to accomplish this\nEscaping Unix supports escape-sequences like \\t, \\n for TAB and newline. Here adding backslash character (\\) in front of t provides the special meaning TAB. We can use the backslash to accomplish the opposite; that is, adding a backslash in front of the special character to inform the shell to treat the character as-it-is.\nFor example, if we pass the * as argument to the echo command, the shell expands the * to file list in the current working directory and passes it to echo that makes echo print all the files. If we escape * as \\* then echo will treat * as * itself.\n$ echo * files hfs $ echo \\* * # not what we wanted $ echo 5 * review 5 files hfs reviews $ echo 5 \\* reviews 5 * reviews $ echo a?* a file with spaces.txt another file with spaces.txt $ echo 'a?*'a?* Quoting There are times where we need to keep space separated words a one single entity instead of list of words since shell uses space as a delimiter to split commands, options and arguments. . For example, we want to pass a sentence to some script as a single argument, we need to wrap the sentence with something to keep the text intact. We can accomplish this using the quotes. In fact, Unix systems support there type of quotes.\n Double quotes or weak quotes Single quotes or strong quotes Backticks or command substitution  Double quotes The shell interpolates the wildcards and special characters such as $, !, \\ and escape sequences \\t, \\n etc.. Since it does not keep all the characters as-they-are, the double quote is also called weak quotes.\nThe $ symbol is used as a prefix in shell variables. If a variable is enclosed inside double-quotes, the value will be substituted. We can escape the $ as \\$ to prevent the interpolation of variables.\necho \"\\$USER: $USER\" $USER: mbose # !! refers to the last command executed # !! will be substituted with the last command # Shell will display the expansion before running the command $ echo \"!!\" echo \"echo \"\\$USER: $USER\"\" echo $USER: mbose In order to create file with special characters like spaces, * in its name, we either need to wrap it inside single or double quotes. The same rules apply when we use these file names as arguments.\n$ touch \"a file with spaces.txt\" $ touch another\\ file\\ with\\ spaces.txt $ ls 'a file with spaces.txt' 'another file with spaces.txt' $ file a\\ file\\ with\\ spaces.txt a file with spaces.txt: empty $ file 'a file with spaces.txt'a file with spaces.txt: empty Single quotes\nWrapping the text using single quotes also known as strong quote suppresses the special meaning of any wildcard, special characters. This is the safest way to quote text. The only restriction is that we cannot have a single-quote inside the text that is wrapped with a pair of single quotes.\n The GNU Bash Manual states that ‘a single quote may not occur between single quotes, even when escaped with a slash \\' it will cause error\n $ echo 'Hello $USER' Hello $USER $ echo \"Hello $USER\" Hello mbose Backticks There is another special set of quotes that is rarely used called backticks that is found under the ESC key. This set of quotes are used for command substitution, that is, the content inside the backticks will be treated and executed as command and the outcome will be replaced by the actual command. The backticks quoted string can be nested within double quotes without losing its special meaning.\n The old way of enabling command substitution is by wrapping the command with a pair of``. However it is recommended to use $() instead of backticks\n $ echo \"Today is date\" Today is date $ echo \"Today is `date`\" Today is Wed Jul 14 21:18:16 IST 2021 # use $(..) instead of `` $ echo \"Today is $(date)\" Today is Wed Jul 14 21:18:16 IST 2021 File System Commands: Part II    # Name Description     1 cp copy files and directories   2 mv rename or move files and directories   3 rm remove files and directories with contents   4 unlink remove single file. a simple version of rm   5 ls list files and directories   6 dir list files and directories; same as ls -C   7 du display the disk usage info of a file or a directory   8 df display free and used space from available hard disks    cp : copy files and directories The cp command is used to copy one or more files and directories. This command can be used to take backups of existing files. The backup will have the timestamps of the copy operations by default. We have options to copy the metadata of the original file along with the contents.\nWARNING: The cp command automatically overrides if the file we are copying has another file in the destination with a same name\n The below 3 options works the same for cp, mv and rm commands\n    Options Description     -v verbose mode, display messages about the action   -f force operations, if possible   -i interactive mode, ask before performing the action    Other options\n   Options Description     -p preserve metadata of source file; owner, timestamp, permissions,..   --parents create full path including directories under the destination   -R recursive copy of directories   -r same as -R    Setup Sample Files and Directories for Demo\n$ mkdir cp_mv_rm $ cd cp_mv_rm $ touch sample_{1..3}.txt $ mkdir backup $ tree . ├── backup ├── sample_1.txt ├── sample_2.txt └── sample_3.txt Copy Demo\n# copy file silently $ cp sample_1.txt backup $ tree backup/ backup/ └── sample_1.txt # cp -v: copy with verbose mode on $ cp -v sample_2.txt backup/ 'sample_2.txt' -\u003e 'backup/sample_2.txt' Preserve file metadata while copying files\n# cp: with and without preserve metadata $ cp sample_1.txt s1a.txt $ cp -p sample_1.txt s1b.txt # more on `ls -l` later # s1b.txt and sample_1.txt has same timestamp: -p effect # s1a.txt has the timestamp at the time of copying $ ls -l -rw-r--r-- 1 mbose admin 0 Jul 10 15:30 s1a.txt -rw-r--r-- 1 mbose admin 0 Jul 10 15:24 s1b.txt -rw-r--r-- 1 mbose admin 0 Jul 10 15:24 sample_1.txt Create source file’s directories inside the target before copy\n# cp --parents : copy full path $ mkdir -pv data/input mkdir: created directory 'data' mkdir: created directory 'data/input' $ touch data/input/demo.csv $ tree data data └── input └── demo.csv $ cp -v data/input/demo.csv backup 'data/input/demo.csv' -\u003e 'backup/demo.csv' # this run creates the entire path $ cp -v --parents data/input/demo.csv backup data -\u003e backup/data data/input -\u003e backup/data/input 'data/input/demo.csv' -\u003e 'backup/data/input/demo.csv' # the 1st cp command copied demo.csv under backup # the 2nd cp copied created data/input and copied the file $ tree . ├── backup │ ├── data │ │ └── input │ │ └── demo.csv │ ├── demo.csv ├── data └── input └── demo.csv Recursive copy\n$ mkdir latest # copy fails $ cp data latest/ cp: -r not specified; omitting directory 'data' $ tree latest/ latest/ # recursive copy $ cp -Rv data latest/ 'data' -\u003e 'latest/data' 'data/input' -\u003e 'latest/data/input' 'data/input/demo.csv' -\u003e 'latest/data/input/demo.csv' mv : move or rename files and directories The mv command can be used either move files from one location to another or rename files\n$ cd cp_mv_rm $ tree . ├── backup ... ├── sample_1.txt ├── sample_2.txt └── sample_3.txt # move file sample_3.txt from current dir to backup $ mv -v sample_3.txt backup/ renamed 'sample_3.txt' -\u003e 'backup/sample_3.txt' $ tree . ├── backup │ └── sample_3.txt ... ├── sample_1.txt └── sample_2.txt # renaming files within same directory $ mv -v sample_1.txt sample_1.csv renamed 'sample_1.txt' -\u003e 'sample_1.csv' # we can rename directories too $ mv -v latest now renamed 'latest' -\u003e 'now' rm : remove files and directories The rm command is used to delete files and directories that are not empty.\nCommon Options: -v, -f, -i - same as cp and -r is recursive delete that is used to remove directories with contents by emptying the contents first and finally deleting the directory itself\nWARNING 1: Unlike Windows, we do not have Recycle Bin in Linux and once deleted the files are gone. Please exercise caution while using rm\nWARNING 2: Use rm -r DIR with caution as it will wipe out the entire contents. Extra caution is needed when the DIR has wildcards\nTIPS: Use the ls command with recursion option ls -R with same argument for rm -r first, verify the list before actually running rm -r\n$ cd cp_mv_rm # remove a file: success $ rm -v sample_1.csv removed 'sample_1.csv' # remove a read-only file: we can say `y` or use -f to delete $ rm -v sample_2.txt rm: remove write-protected regular empty file 'sample_2.txt'? n $ rm -vf sample_2.txt removed 'sample_2.txt' # remove directory that are not empty $ rm -rv data/ removed 'data/input/demo.csv' removed directory 'data/input' removed directory 'data/' unlink : remove a single file This is a simple version of rm that accepts an actual file name as argument and deletes that file. If argument is a wildcard or directory, unlink will error out.\n$ mkdir data $ touch a{1..3}.txt $ ls a1.txt a2.txt a3.txt data # delete a1.txt: success $ unlink a1.txt $ ls a2.txt a3.txt data Errors: wildcards and directories are not valid arguments\n# delete directory: error $ unlink data unlink: cannot unlink 'data': Is a directory # delete multiple files: error $ unlink a* unlink: extra operand ‘a3.txt’ du : display disk usage statistics of files and directories The du command displays the size occupied by a given file or directory passed as argument or current working directory is used as default.\nIf the argument is a directory, the du command displays the size of all its sub-directories and files by default. Options are available to get summary statistics alone\n   Option Description     -s display summary only   -h display size in human readable form - K, M,.. for KB, MB,..   -d N consider N level of subdirectories only   -b consider actual byte size, usually smaller than used size    # size of all directories $ du 4 ./data/input 8 ./data 4 ./temp/data 8 ./temp 4 ./config/db 8 ./config 4 ./shortcuts 36 . # just the summary $ du 36 . # actual vs used size of files # actual size: won't consider holes in a spare file $ du -b -h sample.txt 1.0K sample.txt # used size $ du -h sample.txt 4.0K sample.txt Real life use cases\n# overall size of current user's home directory $ du -sh ~ 540M /home/mbose # run as admin: all user's home directories cd /home $ sudo du -d 1 -h 400M ./admin 70M ./hradmin 30M ./lost+found 350M ./mbose 100M ./mk 150M ./dbauser 150M ./awsuser 1G ./itadmin 2.2G . df : display free and used disk space The df command displays the total, used and available spaces and used percentage of all disks in the system. The most commonly used option is -h to print size in human readable format as in KB, MB, GB etc…\n$ df -h Filesystem Size Used Avail Use% Mounted on overlay 60G 44G 17G 73% / tmpfs 64M 0 64M 0% /dev tmpfs 3.9G 0 3.9G 0% /sys/fs/cgroup /dev/sda1 60G 44G 17G 73% /root /dev/root 2.0G 1.2G 820M 59% /lib/modules shm 64M 0 64M 0% /dev/shm ls : list files and directories The ls command is used to list the files and directories of the current working directory by default. It can accept a file, directory or a wildcard. This is one of the most versatile beginner level commands the we will encounter. The ls command has probably 40-50 different options to control the way the command list the files.\nThis very basic information we get from the ls command is the file and directory names sorted in alphabetic order. In addition to the name, the options enable the ls to control the format of the display and what other metadata about the files can be displayed. Common metadata include\n file type permission settings owner group the owner belongs to file size modification timestamp  ** The permission, owner and group metadata will be discussed in the future chapter on Permissions.\n   Option Description     -1 display one file per row; default is columnar display   -a display hidden files; --all   -A display hidden files but discard . and ..   -F append a unique character at the end to identify file types   -i display inode, a unique number for each file   -l long list: permission, file type, size, owner etc..   -t sort by modification time, newest first   -S sort by file size, largest first   -h display file size in human-readable form; K, M, G, T etc..   -r reverse sorting, used along with -S or -t   -R recursively list contents of sub-directories    For this demo, I have created files with different sizes. I have also copied files with different timestamps using cp --preserve option.\nSetup sample files, directories, links,…\n# create sample files, dirs, links under \"ls_demo\" $ touch sample.txt demo.csv names.txt backup.zip $ mkdir data temp config $ ln -s config cfg $ cp ~/bin/main.sh . # hidden file $ touch .gitignore Simple listings: no options, -1, -a, -A and -F\nEvery directory has two entries; . and .. that refers to the current directory and the parent directory respectively. These entries are not visible by default as Unix treats everything that starts with . as hidden files. If you recollect, these two are used in relative paths as well.\n# ls: current dir as arg, list in alphabetical order, columnar $ ls backup.zip cfg config data demo.csv main.sh names.txt sample.txt temp # ls -1: one entry per line backup.zip cfg config data demo.csv names.txt sample.txt temp # ls -a: display hidden files # . and .. are references to current and parent dirs $ ls -a . .. backup.zip cfg config data demo.csv .gitignore main.sh names.txt sample.txt temp # ls -A : same as -a, discards . and .. $ ls -A backup.zip cfg config data demo.csv .gitignore main.sh names.txt sample.txt temp # ls -F: mark `/, @, *` suffix for dir, link and executable $ ls -F backup.zip cfg@ config/ data/ demo.csv main.sh* names.txt sample.txt temp/ So far, we have seen just the file names being displayed and the options to control what is included and adding symbols to highlight file types. The following examples will display more than just the file names.\nDisplay inode - an unique number allocated to each file\n The inode also known as index node is a data structure that stores file attributes and is referred by an unique integer\n # display inode and file name, one per line $ ls -1i 131218 backup.zip 131222 cfg ... ... 131214 names.txt 131209 sample.txt 131220 temp Display metadata of files, sorted alphabetically\n   Col Description     1 file type (byte 1), Permission (bytes 2-10)   2 number of references, files usually 1, dirs has number of subdirectories including . and ..   3 owner of the file   4 group of the owner   5 file size   6 Month in mmm format   7 day of the month   8 time in HH:MM for files less than one year old    year in YYYY format for files more than one year old   9 file name    # the -l aka long option displays file type, permission # owner, group, file size, modified timestamp and file name -rw-r--r-- 1 mbose admin 0 Jul 11 06:24 backup.zip lrwxrwxrwx 1 mbose admin 6 Jul 11 06:25 cfg -\u003e config drwxr-xr-x 2 mbose admin 4096 Jul 11 06:24 config ... ... -rw-r--r-- 1 mbose admin 0 Jul 11 06:24 sample.txt drwxr-xr-x 2 mbose admin 4096 Jul 11 06:24 temp Sort by modification timestamp -t and file size -S\nFor this demo, we need to use the -l option to compare the sorted order.\n# sort by size descending $ ls -lS drwxr-xr-x 2 mbose admin 4096 Jul 11 06:24 config drwxr-xr-x 3 mbose admin 4096 Jul 11 11:51 data drwxr-xr-x 2 mbose admin 4096 Jul 11 06:24 temp lrwxrwxrwx 1 mbose admin 10 Jul 11 11:52 backup -\u003e backup.zip lrwxrwxrwx 1 mbose admin 6 Jul 11 06:25 cfg -\u003e config -rw-r--r-- 1 mbose admin 0 Jul 11 06:24 backup.zip # sort by modification timestamp descending # set timestamp manually, current timestamp for backup.zip $ touch -d \"5 months ago\" main.sh $ touch backup.zip $ ls -lt -rw-r--r-- 1 mbose admin 0 Jul 11 12:12 backup.zip lrwxrwxrwx 1 mbose admin 10 Jul 11 11:52 backup -\u003e backup.zip drwxr-xr-x 3 mbose admin 4096 Jul 11 11:51 data ... ... -rw-r--r-- 1 mbose admin 0 Jul 11 06:24 sample.txt -rwxr-xr-x 1 mbose admin 0 Feb 11 12:12 main.sh -rw-r--r-- 1 mbose admin 0 Jan 9 2021 names.txt Reverse sort -t\n$ ls -ltr -rw-r--r-- 1 mbose admin 0 Jan 9 2021 names.txt -rwxr-xr-x 1 mbose admin 0 Feb 11 12:12 main.sh -rw-r--r-- 1 mbose admin 0 Jul 11 06:24 sample.txt -rw-r--r-- 1 mbose admin 0 Jul 11 06:24 demo.csv ... dir : list files and directories The dir command performs same actions as the ls command and it may be suitable for people who have come from Windows environment. This command is not available in many OS versions; For example, the Mac systems doesn’t have the dir command. If your system has the dir command, you can use the ls demo to practice on your own.\nSummary In this chapter, we have discussed about the file system and its use in storing and retrieving files and directories. We have also discussed about the absolute and relative paths, wild cards and finally saw practical examples of 15 commands that are used to create and manipulate files and directories, get file lists and usage statistics.\n",
    "description": "",
    "tags": null,
    "title": "1.4: File System: Wildcards",
    "uri": "/part-1/p1-ch3b/"
  },
  {
    "content": "Chapter X grep: Search Files for Patterns Warning This topic is Yet to start…\n ",
    "description": "",
    "tags": null,
    "title": "2.3: Searching Text",
    "uri": "/part-2/p2-ch3/"
  },
  {
    "content": "Chapter X Warning This topic is Yet to start…\n ",
    "description": "",
    "tags": null,
    "title": "3.3: Remote Access Commands",
    "uri": "/part-3/p3-ch4/"
  },
  {
    "content": "Chapter 5 Introduction Linux is a multi-user operating system. In order to access a system, we need credentials, user id and a key or token. I did not use the term “password\"; though it is the predominant way of gaining access, it is not the only way. Once we login to the system, we typically create and view files and directories. Since multiple users can login at the same time, Linux provides mechanism to avoid conflicts in creation and usage of files. This is accomplished thru permissions.\nAuthentication and Authorization When we talk about permissions in Linux, we typically mean who are authorized to access a file and what kind of access the user(s) have. This is the main topic of this chapter. However we must be aware of a different type of permission that deals with gaining access to the system itself before we can access any file. Let us briefly discuss about authentication and authorization.\nAuthentication (AuthN) Authentication is a mechanism that is used by the machine to validate the user’s identity. Typically, it is done using an userid and a password. There are other options like SSH keys that can be used in place of password. This is called Single Factor Authentication (SFA).\nNowadays, systems use Multi-factor Authentication (MFA) that expects a token generated from a trusted device in addition to the SFA. The MFA setup uses physical devices like RSA Tokens or applications such as Google Authenticator that generates numeric token that should be entered after user id and password. Other methods of MFA include OTP - One Time Password, Fingerprint authentication using external applications etc..\nIn the Linux servers, a sysadmin typically creates an user credentials with settings like password length, allowed characters, number of days before user need to change the password. This is not something we need to know as a general user. We will briefly discuss the commands used for awareness. Once you have credentials, then the authorization part takes over.\nThe below commands will be used by Sysadmins, These are listed here for completeness\n You may play around with these commands using google cloud shell, if you are interested. Access the man page for additional information.\n  For demo purpose, I have created few users and groups on GCS that will be used in this chapter and later when we discuss the find command.\n    # Name Description     1 useradd create new user id   2 adduser same as useradd, some installation have this one   3 usermod modify an existing user info   4 userdel delete user   5 groupadd creating new group   6 groupmod modify an existing group info   7 groupdel delete group    Authorization (AuthZ) Authorization deals with access rights, that is, what the user can view, change or do once the authentication is successful. This is the main focus of this chapter. We will look into different aspects of permissions associated with the files and directories with respect to the users and the actions they can perform on these files and directories.\nFile Permissions Everything in Unix is treated as files and every file has an owner and explicit access permission associated with it. The permissions determine who can have access to these files and what type of access they have. We have already discussed about Authentication and Authorization. In this section, we will look into authorization and understand how the system determines who have access to which files and directories.\nPermissions are associated with various actors in the system and the files and directories can have different access associated with them. The owner or the super user or root user can perform various actions in terms of providing permissions to various actors.\n The abbreviations listed in the actors, access and actions tables below are used in the commands related to granting or revoking permission to files and directories.\n Actors\n   Name Abbr Description     User u owner of the file   Group g default group the owner belong to   Others o users that are not part of the group   All a every user in the system    Actions\n   Name Abbr Description     Add + add permission   Remove - remove permission   Assign = discard existing permissions and assign new permissions    Access\n   Name Abbr Description     Read r reading from files     viewing contents of directories   Write w writing into files     create, delete files and directories   Execute x execute files (code)     view or modify metadata of files   User u set same permission as owner; g=u   Group g set same permission as group; o=g   Others o set same permission as others; g=o    Permissions can be assigned to user, default group and others. We can provide three type of access; read, write and execute or assign the existing permission of one actor to another. The combinations ranging from no permission to all permissions. There are 8 combinations derived from these three type of access that can be represented in Octal notation. Numbers 4, 2 and 1 are assigned to read, write and execute and the combinations of these access gets the other values between 0-7.\n We have already seen the permission associated with the file or directory thru ls command with -l option.\n  Permissions can be given using the chmod command either by using actors, actions and access notation or using octal notation\n    Num Permission Description     0 --- no permission   1 --x execute only   2 -w- write only   3 -wx write and execute   4 r-- read only   5 r-x read and execute   6 rw- read and write   7 rwx read, write and execute    Commands: File Permission The following commands are used to\n view existing permissions on files and directories view default permissions used when we create files add / remove / assign permission information about users, groups, files and directories     # Name Description     1 umask view or set default permission   2 ls view permission info using ls -l option   3 stat view permission and other file stats such as size, owner,..   4 mkdir create directory and override the default permission using -m MODE option   5 chmod change permission on files   6 chown change owner of the file   7 chgrp change group name associated with the file   8 id get info about an user; uid, default group and other groups an user is associated with   9 groups get group info of an user   10 passwd change password for current user or user as argument    Setting up the stage In this demo, we are going to view info about users and groups, permission details of files and directories, change owner and group associated with files and directories. In order to perform these activities, we need to setup some user ids, groups and associate users with one or more groups. Let us setup some files and directories for demo.\nSetting up users and groups\nLet us create the following users, groups and relationships between users and groups.\nHere is how the users and group are set based on the roles and responsibilities. We will create the users and groups in google cloud shell, which is an ephemeral or temporary Linux environment. Please refer Appendix at the end of the chapter for the actual commands to setup users and groups. We will run the commands to creates these users and groups as a root user, who is a super-user with more privileges compared to normal users.\nNote: DO NOT Run this on local machine. If you need to practice, use virtual environments or cloud base environments such as Google Cloud Shell or Amazon Elastic Cloud Computing (EC2) instances\n admin (group) : users with admin privilege  sysadmin: monitor the health of the system dbadmin: database administration itadmin: network and security administration   dev (group): developers group  mbose: regular user 1 sholmes: regular user 2; trouble-shooter    Setting up test files and directories\nTop-level directory for sample files\n$ pwd /home/mktutes/trng/linux # top-level directory for demo files $ mkdir 07_perm $ cd 07_perm Sample directories\nWe have created a common directory called bin and each user has a directory under data named after the user id. These user specific directories will be used to demo the chown and chgrp commands.\n$ pwd /home/mktutes/trng/linux/07_perm $ mkdir -pv bin data/{sysadmin,dbadmin,itadmin,mbose,sholmes} mkdir: created directory 'bin' mkdir: created directory 'data' mkdir: created directory 'data/sysadmin' mkdir: created directory 'data/dbadmin' mkdir: created directory 'data/itadmin' mkdir: created directory 'data/mbose' mkdir: created directory 'data/sholmes' Sample files\n$ pwd /home/mktutes/trng/linux/07_perm $ echo 'print(\"Hello World\")' \u003e bin/hello.py $ echo 'echo \"Hello World\"' \u003e bin/hello.sh # create something similar on the other 4 data/\u003cUSER\u003e dirs # we will change the owner and group of these files $ date \u003e data/sysadmin/sample.txt $ date \u003e data/sysadmin/sample.log $ echo \"Hello World\" \u003e data/sysadmin/hello.log umask: set or get default permission In Linux, there is a default permission associated with every file and directory when it is created. This is done by setting default permission at the system level that specifices what permissions are not allowed for the user, group and others.\nWe have already seen the octal representation of permission settings. When we run the umask command without any arguments, it returns the octal representation of permission masked for user, group and others. We can override the default permission by passing new set of permissions in octal format.\n   Option Description     -S display permission as symbolic (u, g, o, …) format instead of octal    The default permission will be usually this. The octal format may be cryptic for beginners. We can use the -S option to display the results in symbolic format. Refer the File Permission section in case you have any doubts about symbolic and octal representation of permission.\n# current permission in octal format $ umask 0022 # current permission in symbolic format $ umask -S u=rwx,g=rx,o=rx  The octal 0022 represents the mask that means nothing is masked for user, write is masked for group and others The symbolic representation shows similar results, where it shows the actual permissions that will be set for user, group and others  ls -l: long listing of files: get permission settings We have already discussed the ls command that is used to list files and directories. It is one of the first commands we have seen that supports various options. In the context of permission, we will revisit the command with option -l that enables a long-list. With ls -l, we get a 9 column output as follows\n file type and permissions number of references associated with the file or directory owner of the file group to which the owner belong file size Month in MMM format Day of the month in DD format Time in HH:MM or Year in YYYY format; Year if the file is older than 6 months else time File name  We are interested in the first column alone, which is typically 10 bytes long. The first byte represents the type of file/directory and bytes 2-10 represents the permission string. The 9 bytes are divided into 3 sets that can have the following values.\n Bytes 2, 5 and 8 are for read permission, can be r or -. Bytes 3, 6 and 9 are for write permission, can be w or -. Bytes 4, 7 and 10 are for execute permission, can be x or -. If there is a - in any of these bytes then the corresponding permission is not enabled.     Bytes Actor     2-4 user   5-7 group   8-10 others    # directory: all permissions for user,  # read and exec for group and others $ ls -l drwxr-xr-x 2 mktutes mktutes 4096 Jul 29 03:57 bin drwxr-xr-x 7 mktutes mktutes 4096 Jul 28 15:26 data # file: both file has different set of permissions # looks like the permissions were changed using `chmod` $ ls -l bin/ -rwxr-x--- 1 mktutes mktutes 57 Jul 29 04:14 hello.py -rwxr-xr-x 1 mktutes mktutes 41 Jul 29 04:02 hello.sh stat: get information about files The stat command produces file status information in a multi-line (human-readable) or single-line (machine-readable). This command produces similar but elaborate file status for a given file or wildcard passed as argument.\nWe can use the stat command as it is to view the permission string along with other file status info or simply use the --format=\"%n %f %a\" or --format=%n %f %A to view the name, type and permission alone.\nstat ARG: as-it-is\n$ stat bin File: bin Size: 4096 Blocks: 8 IO Block: 4096 directory Device: 811h/2065d Inode: 131087 Links: 2 Access: (0755/drwxr-xr-x) Uid: ( 1000/ mktutes) Gid: ( 1001/ mktutes) Access: 2021-07-28 15:26:02.662989810 +0000 Modify: 2021-07-29 03:57:02.251138463 +0000 Change: 2021-07-29 03:57:02.251138463 +0000 $ stat bin/hello. File: bin/hello. Size: 17 Blocks: 8 IO Block: 4096 regular file Device: 811h/2065d Inode: 131089 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 1000/ mktutes) Gid: ( 1001/ mktutes) Access: 2021-07-29 03:57:02.251138463 +0000 Modify: 2021-07-29 03:57:02.251138463 +0000 Change: 2021-07-29 03:57:02.251138463 +0000 stat --format= output\n we can use ---format=FMT_STR or -c FMT_STR\n # permission in symbolic format $ stat --format=\"%n %F %A\" bin bin directory drwxr-xr-x $ stat --format=\"%n %F %A\" bin/hello.py bin/hello.py regular file -rwxr-x--- # permission in octal format $ stat -c \"%n %F %a\" bin bin directory 755 $ stat -c \"%n %F %a\" bin/hello.py bin/hello.py regular file 750 chmod: change mode or permission settings The chmod command is used to add, remove or assign permission settings to the owner, group or others associated with a file or directory. We can change the settings to any of these actors (u, g, o) or the any combination of actors.\nBy default each file and directory will have permission settings associated with it at the time of creation. Though this is assigned by default on files, we can override the permission settings for directories at the time of creation using the -m MODE option with mkdir command. However, we can change the permission of files and directories at the later stage using the chmod command. It can done by the owner of the file or the super user.\nThe chmod command has two syntax variations; one that uses the symbolic representation (u, g, o, +, -, r, w, …) and another that uses the octal representation.\n   Symbolic Representation Octal Representation     Relatively easy to understand Need to remember octal values and combination   Can add, remove or assign permission Only assign permission is supported   Granular access can be provided at actor level Entire permission is overwritten for all 3 actors    chmod with symbols\nHere are some examples\n   Arg Description     u+x add execute permission to user in addition to existing permission settings   g-w remove write permission from group   o=rx discard existing permission for others and assign read and execute   ugo+x add execute permission to user, group and others   a+x same as ugo+x   go= remove all the existing permissions for group and others   g=u assign group the same permission as user   o=u-w assign others the same permission of user and remove the write permission    Check existing permission settings\n$ pwd /home/mktutes/trng/linux/07_perm # chmod: 2 files # user: read and write # group and others: read only $ ls -l bin/ total 8 -rw-r--r-- 1 mktutes mktutes 21 Jul 29 03:49 hello.py -rw-r--r-- 1 mktutes mktutes 19 Jul 29 03:49 hello.sh Impact of the execute permission on files.\n# let us run the shell script as command # fails because user does not have execute permission $ ./bin/hello.sh -bash: ./bin/hello.sh: Permission denied # hello.sh: set execute permission $ chmod u+x bin/hello.sh # user has execute permission now $ ls -l bin/hello.sh -rw-r--r-- 1 mktutes mktutes 41 Jul 29 03:52 hello.py -rwxr--r-- 1 mktutes mktutes 19 Jul 29 03:49 hello.sh # !! Works now $ ./bin/hello.sh Hello World Add/remove write permission\n# let us remove write permission from user on hello.sh $ chmod u-w bin/hello.sh $ ls -l bin/ -r-xr--r-- 1 mktutes mktutes 19 Jul 29 03:49 hello.sh # add some text to hello.sh $ echo 'echo -n \"Date: \"' \u003e\u003e bin/hello.sh -bash: bin/hello.sh: Permission denied # put write permission back, add execute to others and group # chmod: allows multiple set of permission settings $ ls -l bin/hello.sh -r-xr--r-- 1 mktutes mktutes 19 Jul 29 03:49 bin/hello.sh $ chmod u+w,o=rx,g+x bin/hello.sh $ ls -l bin/hello.sh -rwxr-xr-x 1 mktutes mktutes 19 Jul 29 03:49 bin/hello.sh # Let us try writing to hello.sh $ ./bin/hello.sh Hello World $ echo 'echo -n \"Date: \"' \u003e\u003e bin/hello.sh $ echo 'date' \u003e\u003e bin/hello.sh $ ./bin/hello.sh Hello World Date: Thu 29 Jul 2021 04:02:42 AM UTC Add/Remove read permission\n$ ls -l bin/hello.py -rw-r--r-- 1 mktutes mktutes 57 Jul 29 04:14 bin/hello.py $ cat bin/hello.py print(\"Hello World\") $ python3 bin/hello.py Hello World # remove read from user $ chmod u-r bin/hello.py $ ls -l bin/hello.py --wxr--r-- 1 mktutes mktutes 57 Jul 29 04:14 bin/hello.py $ cat bin/hello.py cat: bin/hello.py: Permission denied # add read back to user $ chmod u+r bin/hello.py $ cat bin/hello.py print(\"Hello World\") chmod with octal representation\nThe octal representation has a simpler syntax compared to chmod with symbols. It accepts 3 octal numbers; 0777 for example and assigns corresponding permission combination to user, group and others. Existing permission will be discarded and the new permission will be set for user, group and other at the same time.\n The first, second and third octal numbers represent user, group and others respectively.\n Here are some examples\n   Octal Description     0777 set read, write and execute permission to all (user, group and others)   0644 set read and write permission to user and read-only to group and others   0750 set all permission to user, no permission to others and read-write to group    # user has all permissions, group and others read-only $ ls -l bin/hello.py -rwxr--r-- 1 mktutes mktutes 57 Jul 29 04:14 bin/hello.py # user: all, group: read and execute, others: none $ chmod 0750 bin/hello.py $ ls -l bin/hello.py -rwxr-x--- 1 mktutes mktutes 57 Jul 29 04:14 bin/hello.py id: view user info The id command is used to get information about the current user or any userid passed as argument. Using this command, we can get\n userid and effective user id (numeric value) default group name and group id (numeric) other groups the user belong to.  When the user creates a file or directory, the userid and the default group will be used by default. We can change the ownership using the chown command and one of the groups instead of the default group using the chgrp command.\n**id: current user info\n# user mbose has only one group $ id uid=1001(mbose) gid=1002(mbose) groups=1002(mbose) id: another user info\n# user mktutes is associated with 4 groups $ id mktutes uid=1000(mktutes) gid=1001(mktutes) groups=1001(mktutes),4(adm),27(sudo),999(docker) groups: view group info of an user** The groups command provides a simplified input compared to the id command. It just lists the list of groups associated with the current user, if no argument is provided or lists the groups of another user passed as argument\ngroups: current user\n$ echo $USER hradmin $ groups admin all groups USERID: another user\n# user mktutes has 4 groups $ groups mktutes mktutes : mktutes adm sudo docker chown: change ownership associated with file The chown command is used to change the ownership of a file or set of files. Only the owner or the super-user can make this change.\n$ pwd /home/mktutes/trng/linux/07_perm/data/mbose # super-user $ echo $USER mktutes # sample files $ ls -l -rw-r--r-- 1 mktutes mktutes 0 Jul 29 15:49 sample.csv -rw-r--r-- 1 mktutes mktutes 0 Jul 29 15:49 sample.log -rw-r--r-- 1 mktutes mktutes 0 Jul 29 15:49 sample.txt # chown as super-user, new owner is mbose $ sudo chown -v mbose sample.* changed ownership of 'sample.csv' from mktutes to mbose changed ownership of 'sample.log' from mktutes to mbose changed ownership of 'sample.txt' from mktutes to mbose $ ls -l -rw-r--r-- 1 mbose mktutes 0 Jul 29 15:49 sample.csv -rw-r--r-- 1 mbose mktutes 0 Jul 29 15:49 sample.log -rw-r--r-- 1 mbose mktutes 0 Jul 29 15:49 sample.txt chgrp: change group associated with file The chgrp command is used to change the group associated with a file or set of files. Only the owner or the super-user can make this change.\nIn the previous section, we changed the owner of the files using chown. Let us check the groups that the new owner belongs to and change the group of these files.\n$ id mbose uid=1001(mbose) gid=1003(dev) groups=1003(dev),4(adm),999(docker),1004(all) # chgrp: let us change the group of sample.* files # existing group: mktutes # new group: all $ sudo chgrp -v all sample.* changed group of 'sample.csv' from mktutes to all changed group of 'sample.log' from mktutes to all changed group of 'sample.txt' from mktutes to all $ ls -l sample.* -rw-r--r-- 1 mbose all 0 Jul 29 15:49 sample.csv -rw-r--r-- 1 mbose all 0 Jul 29 15:49 sample.log -rw-r--r-- 1 mbose all 0 Jul 29 15:49 sample.txt passwd: change password The passwd command is used to change or reset the password. Regular users can run this command without any argument to reset their password. The super-user can reset the password for other users by passing the userid as argument\nChange Password: Success\n$ echo $USER mbose # enter current and new password $ passwd Changing password for mbose. Current password: New password: Retype new password: passwd: password updated successfully Invalid current password: ABORT\n$ passwd Changing password for mbose. Current password: passwd: Authentication token manipulation error passwd: password unchanged Retype new password: Mismatch\n$ passwd Changing password for mbose. Current password: New password: Retype new password: Sorry, passwords do not match. passwd: Authentication token manipulation error passwd: password unchanged Reset password as super-user using the sudo command\n$ sudo passwd mbose New password: Retype new password: passwd: password updated successfully Create Users and Groups Caution:\n The below commands are for demo only. If you are root user or have super-user privilege on a Linux Server, you can try these commands. DO NOT TRY this on your Linux Desktop. The sudo and su commands should be treated with caution.\n Setup Users and Groups\n# sudo: run commands as super-user and create home dirs for users $ sudo mkdir sysadmin dbadmin itadmin mbose sholmes # create groups $ sudo groupadd admin $ sudo groupadd dev $ sudo groupadd all # create users $ sudo useradd sysadmin -d /home/sysadmin -g admin -G all $ sudo useradd dbadmin -d /home/dbadmin -g admin -G all $ sudo useradd itadmin -d /home/itadmin -g admin -G all $ sudo useradd mbose -d /home/mbose -g dev -G all $ sudo useradd sholmes -d /home/sholmes -g dev -G all ",
    "description": "",
    "tags": null,
    "title": "1.5: Permission",
    "uri": "/part-1/p1-ch4/"
  },
  {
    "content": "Chapter X sed: Search and Replace Text in Files Warning This topic is Yet to start…\n ",
    "description": "",
    "tags": null,
    "title": "2.4: Text Substitution",
    "uri": "/part-2/p2-ch4/"
  },
  {
    "content": "Chapter X Warning This topic is Yet to start…\n ",
    "description": "",
    "tags": null,
    "title": "3.4: Archival commands",
    "uri": "/part-3/p3-ch3/"
  },
  {
    "content": "Chapter 6 Introduction So far, we ran commands that displayed text on screen, be it errors or intended output. In cases like the cp -i command, the system expects user input to continue the execution. The system uses the keyboard as Standard Input and the monitor as Standard Output and Standard Error.\nLet us look into one of the most powerful features of Unix called IO Redirection. It enables us to use files instead of the keyboard and monitor as standard input and output. We will discuss the usage of pipes - | to pass the output of one command as input to another. Using the pipes, we can build a command pipeline to solve complex problems using several commands that run sequentially.\n Using the IO redirection and the pipes in particular, we can bring synergy by using multiple commands together where the end result is greater than the sum of the parts (commands).\n How it works ? Many commands use stdin if no arguments are provided. For example, the cat command that display the contents of a file, uses the stdin if no file its provided. It waits for the user to type something, when the user press the enter key, displays the content and this keeps going until cat receives CTRL-D key.\n$ cat Hello, World Hello, World Good Bye Good Bye CTRL-D Another Example Let us consider the following scenario; We have a comma-delimited student data file that has students grade and scores. One of the requirement is to get the counts of students who received greater that 50 score points and group the count by grade(3rd, 4th, 8th grades…). We can write a program or we can use the following set of commands\n Note: The below command pipeline is just for demonstration. We will look into the commands used in the demo later.\n  awk: extract all records that has score greater than 50. awk: extract just the grade alone. sort: sort output from awk by grade. uniq -c: get count by grade; displays count followed by grade. awk: reformat output by swapping counts and grades.  Here is some sample records\n# studentId,lastName,firstName,gender,grade,score $ tail student.csv A0000078,Clark,Joyce,F,04,92 A0000079,Stevenson,Laura,F,06,90 A0000080,Jackson,Melissa,F,07,88 A0000081,Rogers,Matthew,M,06,90 Here is how the command will look\n$ awk -F, '$NF \u003e= 50 {print $5}' student.csv | sort | uniq -c | awk '{print $2, $1}' 03 2 04 3 05 4 06 5 07 3 08 2 # sum up the counts above, run awk with `$NF \u003c 50` to verify $ wc -l student.csv 23 student.csv Another way to solve this by writing a program. Let us create a python script and compare the command-line solution against it\n1 # name: counts.py  2 # purpose:  3 # reads 'student.csv', filter the records by score \u003e=50 4 # accumulate the counts by grade and display the results 5 6 stats = dict() 7 with open('student.csv') as fh: 8 for rec in fh: 9 data = rec.strip().split(\",\") 10 score = data[-1] 11 score = int(score) 12 if score \u003c 50: 13 continue 14 grade = data[-2] 15 stats[grade] = stats.get(grade, 0) + 1 16 17 for grade in sorted(stats): 18 print(f\"{grade} {stats[grade]}\") $ python3 counts.py 03 2 04 3 05 4 06 5 07 3 08 2 Here is the command sequence we used, It looks pretty small, right?\n$ awk -F, '$NF \u003e= 50 {print $5}' student.csv | sort | uniq -c | awk '{print $2, $1}' Using commands and redirection, we can build a quick prototype and validate before developing code.\nRedirection In Unix, everything is treated as a file. We have seen that keyboard and monitor are used as default stdin and stdout respectively. Since Unix treats the devices as files, we can substitute files in place of these devices. This is called IO Redirection.\nIn order to accomplish the redirection, we use special characters to instruct the shell to read/write from files instead of the devices. A file will be coded after the symbols typically.\n   Symbol Description     \u003c standard input   \u003e standard output   \u003e\u003e standard output, append mode   2\u003e standard error   2\u003e\u003e standard error, append mode    Here are some additional syntax to redirect both stdout and stderr into same file.\n   Symbol Description     \u003e FILE 2\u003e\u00261 standard output and error to same file   \u0026\u003e same as 2\u003e\u00261, simplified version in latest versions   \u0026\u003e\u003e standard output and error to same file, append mode   \u003e\u0026 same as \u0026\u003e, not preferred    Note\n \u003e FILE 2\u003e\u00261 works in most of the shells including bash \u0026\u003e \u0026\u003e\u003e are bash specific. \u003e\u0026 is supported in bash, ksh, csh shells unlike \u0026\u003e\u003e for append, \u003e\u003e\u0026 throws up syntax error. for bash, it is preferable to use \u0026\u003e or \u003e FILE 2\u003e\u00261  We will look into these combination later. Let us first discuss stdin, stdout and stderr.\nStandard Input: \u003c The commands we have seen so far are not great examples to demonstrate the stdin usage. Later in this series, we will discuss thetr and xargs commands that accepts data from stdin. For demo, let us look at how it works using the commands we have seen so far.\nThe cat command without any argument, reads from keyboard (stdin). We can pass the contents of a file instead of stdin using the \u003c symbol.\n$ cat \u003c hello.txt Hello World $ cat hello.txt Hello World Though both versions have same effect, the first cat reads from the standard input and display the contents whereas the second cat opens the file, read it and display the contents.\nStandard Output: \u003e and \u003e\u003e So far, the commands we ran either finished quietly (mkdir) or displayed the output on the screen (ls). However we may want to store the results for future reference. The stdout redirection comes in handy in situations like this.\nWe have two ways of redirecting the standard output, write and append mode. We usse \u003e for write and \u003e\u003e for appennd. When we use \u003e, the contents of the file will be overwritten, if the file exists already whereas \u003e\u003e appends the contents to an existing file. In both cases, the file is created if it does not exist.\n# output redirected to file_list.txt $ ls -1 \u003e file_list.txt $ cat file_list.txt counts.py demo.txt file_list.txt sample.txt # append contents $ echo \"List from parent dir\" \u003e\u003e file_list.txt $ ls -1 ../ \u003e\u003e file_list.txt $ cat file_list.txt counts.py demo.txt file_list.txt sample.txt List from parent dir files hfs Capturing Keyboard Input and Create Files\nThe stdout is a great way to capture the output of the commands that can be used for future reference. Most importantly, we can create our own simple files to play around learning commands.\nIn order to create our own files with complex data, we need to learn how to use the editors like Vi or write programs to create the files. However, we can use the stdout to capture the input from keyboard and store the contents in a file using the cat \u003e file_name syntax. Once the command iss executed, whatever we type will be captured in the file we provided after \u003e until CTRL-D is pressed. We can use \u003e\u003e instead of \u003e to append the data into an existing file.\nLet us see it in action\n# cat: waits for user to enter data. will be written to names.txt # commad exits when CTRL-D is pressed $ cat \u003e names.txt lastName,FirstName,Score,EndOfRec Bell,Isac,75,Z Pitt,Dirk,89,Z Zavala,Joe,99,Z CTRL-D $ cat names.txt lastName,FirstName,Score,EndOfRec Bell,Isac,75,Z Pitt,Dirk,89,Z Zavala,Joe,99,Z # append some more records $ cat \u003e\u003e names.txt Smith-Pitt,Lauren,87,Z Cabrillo,Juan,89,Z CTRL-D $ cat names.txt Bell,Isac,75,Z Pitt,Dirk,89,Z Zavala,Joe,99,Z Smith-Pitt,Lauren,87,Z Cabrillo,Juan,89,Z Standard Error 2\u003e The standard error or stderr is where the commands redirect the error message. These messages also uses screen as default and often we cannot tell whether the message is from stdout or stderr.\nFor example, the mkdir command with -v option displays a message created directory if it is successful and displays an error message cannot create directory if it is not successful. The error is displayed with or without the -v option.\nIn the example below, the first message is from stdout and the second one is from stderr. We may not be able distinguish by just looking at the messages, however if we use the redirection symbols \u003e and 2\u003e that corresponds to stdout and stderr, we can see the difference\n$ mkdir -v data mkdir: created directory 'data' $ mkdir -v data mkdir: cannot create directory ‘data’: File exists Let us redirect the messages.\n# setup $ mkdir redirection $ cd redirection $ mkdir data temp $ ls data temp # redirect stdout $ mkdir -v data data/input \u003e mkdir.log mkdir: cannot create directory ‘data’: File exists $ cat mkdir.log mkdir: created directory 'data/input' Here mkdir -v data failed since there is a data directory already and it was not captured in the \u003e mkdir.log because \u003e is to redirect stdout only and the error message still used the screen as stderr. The mkdir.log has the success message about the creation of input directory inside data.\nNow we can use the 2\u003e to capture stdout.\n# this command produces both error and success messages $ mkdir -v data/input data 2\u003e mkdir.err mkdir: created directory 'data' $ cat mkdir.err mkdir: cannot create directory ‘data/input’: No such file or directory In the above example, we see that the error message is redirected into the file and success message is redirected to the screen. The simplest way to capture both error and success messages is by coding both \u003e and 2\u003e.\n# nothing will be displayed for this run $ mkdir -v data/input data 2\u003e mkdir.err \u003e mkdir.log $ cat mkdir.log mkdir: created directory 'data' $ cat mkdir.err mkdir: cannot create directory ‘data/input’: No such file or directory What if we do not need the error messages ? At times, we do not need the error messages to be displayed on screen or captured in files. We can redirect the stderr to a special device file called /dev/null that serves as a trash and data redirected there are gone forever.\n The /dev/null is a write only device file that can be used to redirect anything we want to discard forever. It is also called bit bucket or blackhole of the system. Whatever has been redirected to it is swallowed up never see the light of the day\n Redirecting stderr to /dev/null is very useful in cases like permission denied errors when we do recursive operations. It is also helpful in discarding expected errors like the one mkdir throws when we try to create a directory that is already there.\n# /dev/null: a 'character block' device file $ ls -l /dev/null crw-rw-rw- 1 root root 1, 3 Jul 16 09:29 /dev/null $ mkdir -v data mkdir: created directory 'data' $ mkdir -v data mkdir: cannot create directory ‘data/input’: No such file or directory # error message discarded $ mkdir -v data 2\u003e /dev/null stdout and stderr to same file In the previous sections, we have seen examples to redirect the stdout and stderr using \u003e and 2\u003e respectively. What if we want to capture the data from stdout and stderr into the same file ? Can we do it ? One naive way we may logically think of is to use \u003e\u003e and 2\u003e\u003e passing the same file.\n$ mkdir -v data data/input data/output \u003e\u003e mkdir.log 2\u003e\u003e mkdir.loh $ cat mkdir.log mkdir: cannot create directory ‘data’: File exists mkdir: created directory 'data/input' mkdir: created directory 'data/output' Though the above example works, the shell provides better ways to deal with this situation. There are there ways we can accomplish this and these are listed in the order of preference.\n \u003e FILE 2\u003e\u00261: Works in most of the shells; bash, ksh, csh. Use this if you need shell portability or if you work on multiple shell types. This syntax means, redirect stdout to FILE and stderr to \u00261 also know file descriptor 1 that points to stdout. Since stdout already points to FILE, data from both streams end up in the same file. \u0026\u003e or \u0026\u003e\u003e: This is a short-hand notation of \u003e FILE 2\u003e\u00261 that works only on bash and zsh shells \u003e\u0026 is not a preferred syntax and it works the same way as \u0026\u003e however we cannot perform append; \u003e\u003e\u0026 throws syntax errors.  Let us look at this in action. In each cases we will remove the input and output directories before running the mkdir command.\nusing \u003e FILE 2\u003e\u00261\n$ mkdir -v data data/input data/output \u003e mkdir.log 2\u003e\u00261 $ cat mkdir.log mkdir: cannot create directory ‘data’: File exists mkdir: created directory 'data/input' mkdir: created directory 'data/output' using \u0026\u003e FILE\n$ mkdir -v data data/input data/output \u0026\u003e mkdir.log $ cat mkdir.log mkdir: cannot create directory ‘data’: File exists mkdir: created directory 'data/input' mkdir: created directory 'data/output' using \u003e\u0026 FILE\nThis is not a preferable way of redirecting standard output and error into a same file. This is covered for the sake of completeness.\n$ mkdir -v data data/input data/output \u003e\u0026 mkdir.log $ cat mkdir.log mkdir: cannot create directory ‘data’: File exists mkdir: created directory 'data/input' mkdir: created directory 'data/output' Emptying an existing File One of the simplest ways to discard the contents of an existing file and leave it empty is by simply using one of the following syntax using stdout redirection\n \u003e FILE: empties the file by truncating to zero byte length. may not work in all shells.\n:\u003e FILE syntax; same as \u003e FILE but works on all shells. If the file is not present then it creates an empty file  $ echo \"hello\" \u003e hello.txt # 6 bytes long file $ ls -l hello.txt -rw-r--r-- 1 mbose admin 6 Jul 16 10:10 hello.txt $ \u003e hello.txt $ wc -l hello.txt 0 0 0 hello.txt $ file hello.txt hello.txt: empty Pipes | The pipe takes the concept of redirection further. Use the pipes, we can redirect the output of one command as an input to another. Like the plumbing system, we can run a large set of commands sequentially by passing the output of one command as input to another. This concept is useful to filter or reformat the output of commands in every stage and discard any data that is not needed.\n When we use pipe | to construct a sequence of commands, only the output of the last command may be displayed on screen. We can redirect that into an output file, if needed\n Let us look into simple use cases now. We will use the | heavily as we discuss more commands in the future\nUse case 1: Get DD MMMM YYYY from the date command Let us start with a trivial example. The date command displays current date and time in DDD DD MMM YYYY HH:MM:SS AM|PM TZ format. We need to extract 11 bytes; position 5-15. This can be done easily using data format string \"%d %b %Y\". Here is one way to solve it using pipes\n use head -c15 to get bytes 1-15 pipe the output to tail -c11  $ date Fri 16 Jul 2021 11:26:09 AM UTC $ date | head -c15 | tail -c11 16 Jul 2021 Use case 2: Get record 16-20 from a file and add line numbers Based on what we know already, the head and tail command can be used to see the top and bottom portion of a given file and the nl or cat command can be used to add line numbers. In this case, we have been asked to get the records 16-20 and add line numbers to the filtered output.\nHere is one way to solve this\n head -20 to get the first 20 records redirect the output of the head -20 to tail -5 redirect the output to the nl -s, command where -s, adds a comma-delimiter after the line number command sequence: nl FILE| head -20 | tail -5 |nl -s,  # get record count $ wc -l student.csv 23 student.csv # records 16-20 are displayed out of the 23 records # nl is used to add the line numbers before extracting records $ nl student.csv | head -20 | tail -5 16 A0000092,Kelley,Jerry,M,03,73 17 A0000093,Massey,Brian,M,07,84 18 A0000094,Jones,Anthony,M,05,100 19 A0000095,Martinez,Henry,M,04,65 20 A0000096,Martin,Lindsay,F,04,45 Note: The first nl command here is simply used to demonstrate that we are actually getting records 16-20 by numbering the records in advance. We can drop it and start with the head command.\n$ head -20 student.csv| tail -5 A0000092,Kelley,Jerry,M,03,73 A0000093,Massey,Brian,M,07,84 A0000094,Jones,Anthony,M,05,100 A0000095,Martinez,Henry,M,04,65 A0000096,Martin,Lindsay,F,04,45 Use case 3: Get first 10 records excluding header The delimited files usually contain a header as first record. We need to discard the header. There are couple of ways we can do this\nHere is a sample file\n$ head -2 student.csv studentId,lastName,firstName,gender,grade,score A0000078,Clark,Joyce,F,04,92 Option 1:\n use tail -n +2 FILE to discard the first record pipe the output to head command  $ tail -n +2 student.csv | head A0000078,Clark,Joyce,F,04,92 A0000079,Stevenson,Laura,F,06,90 A0000080,Jackson,Melissa,F,07,88 ... ... A0000085,Smith,Lance,M,04,44 A0000086,Arias,Corey,M,07,61 A0000087,Nguyen,Sarah,F,06,88 Option 2:\n use head -11 student.csv to get first 11 records pipe the output to tail command  $ head -11 student.csv | tail A0000078,Clark,Joyce,F,04,92 A0000079,Stevenson,Laura,F,06,90 A0000080,Jackson,Melissa,F,07,88 ... ... A0000085,Smith,Lance,M,04,44 A0000086,Arias,Corey,M,07,61 A0000087,Nguyen,Sarah,F,06,88 The tee command: | and \u003e Here is one more feature before we wrap up our discussions. What if we want to view the output of a long running command while it is executing at the same time save the output in a file for future use ?\nFrom what we know already, this is how we can accomplish\n redirect the output of the command to a file CMD \u003e FILE or CMD \u003e\u003e FILE open another terminal and follow the file using tail -f FILE or tail -F FILE  There is a another way. We can use the tee command to perform the same operation without leaving the terminal. We simply pipe the command’s output to the tee command as in CMD | tee FILE.\n The tee command derives it name from the T-Junction in the pipelines where the flow is diverted from input into two pipes. Pretty cool, right !!\n    Option Description     -a append output to an existing file    Here are couple of examples\n$ echo \"Hello\" | tee hello.txt Hello $ cat hello.txt Hello $ echo \"Bye\" | tee hello.txt Bye $ cat hello.txt Bye $ echo \"Hello\" | tee hello.txt Hello $ echo \"Bye\" | tee -a hello.txt Bye $ cat hello.txt Hello Bye Points to remember  keyboard and screen are the default standard input and output used by the commands screen is used for both standard output and error we can use files instead and the files can be passed as stdin or stdout using special characters CMD \u003c FILE is the syntax to pass contents of FILE as stdin CMD \u003e FILE and CMD 2\u003e FILE are stdout and stderr \u003e\u003e and 2\u003e\u003e are used to append the contents to an existing file CMD \u003e FILE 2\u003e\u00261 is to redirect stdout and stderr into the same file. We can also use CMD \u0026\u003e FILE Pipes are used to redirect output of one command as input to another CMD | tee FILE command is used to both display contents on screen and save into FILE.  Endnote Though this chapter packs a lot of action, we have not seen the full potential of redirection yet. We will look into the uses when we discuss file manipulation and text processing commands. This is one of the key concept to understand and internalize to use the command line better.\n",
    "description": "",
    "tags": null,
    "title": "1.6: IO Redirection",
    "uri": "/part-1/p1-ch5/"
  },
  {
    "content": "Chapter X awk: Amazing Text Processor Warning This topic is Yet to start…\n ",
    "description": "",
    "tags": null,
    "title": "2.4: AWK programming Language",
    "uri": "/part-2/p2-ch5/"
  },
  {
    "content": "Chapter X Warning This topic is Yet to start…\n ",
    "description": "",
    "tags": null,
    "title": "3.5: The \"find\" Command",
    "uri": "/part-3/p3-ch5/"
  },
  {
    "content": "Introduction We know how to create directories and files, empty files at least !! using the mkdir and the touch commands respectively. In this chapter let us look into the ways to view files. Though viewing files seem like a simple task, as in double-clicking a file in Windows, Linux provides several commands to view the files.\nSince we have not discussed about way to create our own files, we will use common text files available in the system, the files in /etc directory such as /etc/shells or /etc/passwd. Another good candidate is ~/.bash_history that may have around 500 lines.\n Simplicity is one of the core philosophy of Unix-based systems. We have several simple commands, each catering to a specific way of viewing files instead of one complex command with multiple options to view files.\n Command List: View Files The following commands can be used to view files in different ways such as\n view entire file on the screen view some records from the start / end of the file view one page at a time with options to scroll back and forth view octal, ascii, binary and hexadecimal representations fold longer records and view view live files created by other processes without intruding the writing format and view files with page number, header, date  …and more\nHere is the list of commands we will be discussing in this chapter.\n   # Name Description     1 cat view file(s), displayed on the screen   2 tac view file(s), records displayed in reverse order; last record first LIFO. May not be available in some OS versions   3 rev view records in reverse order, like cat but each record is displayed in reverse order   4 nl like cat, adds line number as prefix   5 wc display number of lines, words and characters of the file(s)   6 head display first 10 lines of file(s) by default   7 tail display last 10 lines of file(s) by default   8 less display contents of a file, one line at a time. use spacebar and b to page down and page up and q to quit display   9 more like the less command; older version and limited navigation features   10 od display files as ascii, octal, hexadecimal dump, useful in analysing binary files   11 fold wrap each record to fit a specific width   12 pr convert text file for printing with pagination and header    cat: view files The cat command simply displays the contents of the file on the screen. It works fine to view small files and not a good choice to view large files. If we provide a wildcard instead of an actual file, cat simply displays all files as a single entity. The display looks like the files are concatenated and displayed.\nHere is an example\n# /etc/shells: supported shells  $ cat /etc/shells # List of acceptable shells for chpass(1). # Ftpd will not allow users to connect who are not using # one of these shells. /bin/bash /bin/csh /bin/ksh /bin/sh Commonly used options\n   Option Description     -n display line number   -b display line number; ignore blank lines   -e show end of the line as $    $ cat -n /etc/shells 1\t# List of acceptable shells for chpass(1). 2\t# Ftpd will not allow users to connect who are not using 3\t# one of these shells. 4\t5\t/bin/bash 6\t/bin/csh 7\t/bin/ksh 8\t/bin/sh # display '$' as end-of-line, number non-empty lines $ cat -b -e /etc/shells 1\t# List of acceptable shells for chpass(1).$ 2\t# Ftpd will not allow users to connect who are not using$ 3\t# one of these shells.$ $ 4\t/bin/bash$ 5\t/bin/csh$ 6\t/bin/ksh$ 7\t/bin/sh$ Sometimes, we may not be able to figure out what is wrong with the data due to non-printable characters since these characters are not visible (Tab, newline etc..). We can use the following options to view the non-printable characters that are usually displayed with a ^ or M- prefix.\n   Option Description     -v show non-printable characters except for TAB and newline   -T show tabs as ^I   -t same as -vT   -E show line endings as $   -e same as -vE   -A show all non-printable characters    The file non-printable-chars.txt has TAB, newline and other non-printable characters that are not visible by default.\n$ cat non-printable-chars.txt This is a standard text with alphabets and spaces is used to suspend a running process The tab is used to display text in columnar format For example 1001 Smith John Male 1002 Doe Jane Female Non-printable characters Let us use the -A to print all non-printable characters first. In the below demo\n ^Z: shows the CTRL-Z that was originally invisible (-v) $: displayed on behalf of newline (-E) ^I: displayed on behalf of tab (-T)  $ cat -A non-printable-chars.txt This is a standard text with alphabets and spaces$ ^Z is used to suspend a running process$ The tab is used to display text in columnar format$ For example$ ^I1001^ISmith^IJohn^IMale$ ^I1002^IDoe^IJane^IFemale$ $ Non-printable characters $ tac: view files in the reverse order The tac command displays the file in reverse order, last record first and first record at the end. The command itself is derived by reverse spelling of cat. Yes, Unix has its own quirks and insider jokes !!\nExample\n# run cat on the same command for comparison $ tac /etc/shells /bin/sh /bin/ksh /bin/csh /bin/bash # one of these shells. # Ftpd will not allow users to connect who are not using # List of acceptable shells for chpass(1). rev: reverse lines The reverse command displays each record in the reverse order. It is like the tac command but instead of reversing records, it reverses characters in each record. In the upcoming chapters, we will discuss one of the powerful concepts in unix-like systems called redirection that can be used to combine tac and rev to reverse the entire file byte-by-byte.\n$ rev /etc/shells .)1(ssaphc rof sllehs elbatpecca fo tsiL # gnisu ton era ohw tcennoc ot sresu wolla ton lliw dptF # .sllehs eseht fo eno # hsab/nib/ hsc/nib/ hsk/nib/ hs/nib/ nl: number the lines from files The cat command has the -n and -b options to add line-numbers to each record. The nl command provides more options such as overriding the starting number and increment by 1. In addition to that, we can control the width and justification of the line numbers.\n   Option Description     -v N override starting number; defaults 1   -i N override increment, defaults 1   -w N width of the line numbers with leading spaces   -n OPT formatting options; ln: left-justified, rn: right justified    rz: right-justified with leading zeroes    Here is a demo of all options listed above.\n$ nl -v 10 -i 5 -w 7 -n rz /etc/shells 0000010 # List of acceptable shells for chpass(1). 0000015 # Ftpd will not allow users to connect who are not using 0000020 # one of these shells. 0000025 /bin/bash wc : display lines, words and characters counts The wc command displays the number of records, words and characters of a given file. In other words, it counts the number of newlines \\n, space separated words and characters and display along with the file name provided as argument. This is a great way of getting an idea without even opening the file. By default, wc displays all three statistics.\n NOTE: If you manually count the characters, you may get lesser number because wc includes the non-printable newline \\n in the characters count.\n    Option Description     -l display line count ONLY   -w display words count ONLY   -c display characters count ONLY    # display lines, words and chars count of /etc/shells $ wc /etc/shells 8 12 134 /etc/shells # `wc FILE` is same as 'wc -lwc FILE' or 'wc -l -w -c FILE' $ wc -lwc /etc/shells 8 12 134 /etc/shells # display lines count  $ wc -l /etc/shells 8 /etc/shells # display chars count  $ wc -c /etc/shells 134 /etc/shells # display words and chars count  $ wc -wc /etc/shells 12 134 /etc/shells head: display part of the records at the TOP The head command displays the first 10 records from the given file. This is really helpful in viewing a sample of really big files.\n   Option Description     -C N display N characters   -N display first N lines   -n N same as -N    I have a names.txt file with line number and names for this demo that has 13 records.\n$ head names.txt 1. alan 2. beth 3. bob ... ... 9. eion 10. fred Limit or extend the number of lines to be displayed\n# override default MAX=10 $ head -n 3 names.txt 1. alan 2. beth 3. bob $ head -4 names.txt 1. alan 2. beth 3. bob 4. cathy Limit characters instead of lines. This option is usually used with the /dev/urandom device file that generates random characters infinitely.\n# the prompt '$' is displayed after '3.' # since the -c option truncates at mid-line $ head -c25 names.txt 1. alan 2. beth 3. $ tail: display part of the records from the BOTTOM The tail command works pretty much similar as the head, just at the end of the file. It has an additional couple of additional features.\nWe can watch a live file that is being updated by another process without interfering. This is very helpful to watch logs and files from long running processes to proactively take decisions based on the outcome rather than waiting for the process to finish. The file will be monitored until we terminate the watch using CTRL-C.\nAnother feature is to skip first N records, which is useful to skip header records while process a delimited file.\nWe can use all the options mentioned in the head and here are some additional options.\n   Option Description     -n +N display from the Nth line onwards   -f follow a live file, error out if file not exists   -F same as -f, waits for file to appear   --pid=PID used along with -f, terminates after PID is done    Display from 10th record\n$ tail -n +10 names.txt 10. fred 11. freya 12. felicity 13. gaea Live monitoring of file using -F or -f\n$ ls tr.txt names.txt # another process is periodically writing to 'tail.log' # we can open this file and add text or write script to # simulate the live file scenario # tail -f FILE: fails if file not found $ tail -f tail.log tail: cannot open 'tail.log' for reading: No such file or directory tail: no files remaining # tail -F FILE: waits till the file is being created # if file being followed is renamed,  #. tail -F follows the new file $ tail -F tail.log tail: cannot open 'tail.log' for reading: No such file or directory tail: 'tail.log' has appeared; following new file 1 2 ... ^C less: display one page at a time The less command can be used to view files, one screen at a time. It provides sub-commands to scroll-up, scroll-down page wise or line-by-line and to quit when we no longer want to continue. This is also called a pager command that is used in the man command as well as other manual or help commands such as perldoc, pydoc, …\n We cannot document a demo on the less or more command. You are welcome to try the following sub-commands with man, more or less commands\n Sub-commands\n f : go to next page spacebar : same as f, go to next page b : go to previous page ENTER : scroll one line down DOWN arrow : scroll one line down UP arrow : scroll one line up h : list sub-commands and get help q : quit less command /SRCH : search forward text or pattern ?SRCH : search backward text or pattern n : find next search with /SRCH, previous search with ?SRCH N : find previous search with /SRCH, next search with ?SRCH \u0026/SRCH : display only the lines that has SRCH text or pattern  more: display one page at a time more is the oldest version of the less command. We can use the same sub-commands such f, b, q to move forward, backward and quit. This commands is listed for the sake of completeness. use the less command instead.\n One notable change between less and more is that more automatically exits when we reach end of file whereas less needs an explicit q sub-command to quit browsing the file\n od: dump file in octal, hex and ascii formats The od command display the contents; individual characters or bytes of the file in octal, hexadecimal, ascii and other formats. By default, it takes 2 bytes at a time and display the result in octal format at a time.\n The od command comes in handy understanding dump files or data file that contains garbled characters that is not explainable by viewing thru naked eye\n For example, the word Hello_World will be displayed as 062510 066154 057557 067527 066162 000144. If we convert the octal number to hexadecimal, it would be 6548 6C6C 5F6F 6F57 6C72 64. The ASCII values for these hex numbers are eH ll _o oW lr d. If you swap each of these two bytes ASCII values, you will get He ll o_ Wo rl d =\u003e Hello_World. If you want to know why we need to swap, google Little Endian. Or better, forget you read this and use one of the options to get octal, hex or ascii dump.\nThe first word in each line of the display is the offset in octal format by default that starts with zero. We can use\n   Option Description     -a select named characters - newline and tab displayed as nl and ht   -c display printable chars and escape sequences with leading \\   -b display in octal format   -x display in hexadecimal format   -Ad display offset in decimal format, default is octal   -Ax display offset in hexadecimal format, default is octal   -j N skip N bytes from the start   -N N limit to N bytes of display    Sample File\n# we have a sample file with one record that has some # ascii chars, tab and newline. $ cat sample.txt Hello World # Let us check the tab and newline first; ^I: TAB, $: newline $ cat -A sample.txt Hello^IWorld$ Octal Dump\n# octal format: ASCII 0o110 is H, ... $ od -b sample.txt 0000000 110 145 154 154 157 011 127 157 162 154 144 012 0000014 # hexadecimal format: little endian $ od -x sample.txt 0000000 6548 6c6c 096f 6f57 6c72 0a64 0000014 # ascii with named characters: ht = TAB, nl = newline $ od -a sample.txt 0000000 H e l l o ht W o r l d nl 0000014 # ascii with escape sequences: \\t, \\n $ od -c sample.txt 0000000 H e l l o \\t W o r l d \\n 0000014 Offset Display format using `-A: Octal by default\n# '-Ax' : offset in hexadecimal format - 00 0c $ od -c -Ax sample.txt 000000 H e l l o \\t W o r l d \\n 00000c # '-Ad' : offset in decimal format - 0 12 $ od -c -Ad sample.txt 0000000 H e l l o \\t W o r l d \\n 0000012 Skip -j N and Limit -N N dump\n# limit to 5 bytes $ od -N5 -a sample.txt 0000000 H e l l o 0000005 # skip 6 bytes $ od -j6 -a sample.txt 0000006 W o r l d nl 0000014 # skip 6 bytes, limit 5 bytes $ od -j6 -N5 -a sample.txt 0000006 W o r l d 0000013 fold: wrap records to fit specific width The fold command is used to limit the maximum number of characters displayed per line and if a record has more characters then the rest is wrapped to next line. Using this command, we can ensure that display fits within a viewable area of the screen and there is no need to scroll left and right.\nBy default, fold limits 80 characters per line. There are historical reasons for this. The terminals of the old days used to have 24x80 display; 24 rows and 80 columns. We can override this.\n   Option Description     -w N limit width of record to N bytes, default is 80   -s break at space if possible, not in the middle of the text    For this demo, i have created a file with one long record with 130 bytes and 10 words, each word of 12 bytes long delimited by spaces.\n# single record - numbered $ nl long_record.txt 1 A00000000001 A00000000002 A00000000003 A00000000004 A00000000005 A00000000006 A00000000007 A00000000008 A00000000009 A00000000010 # two recs split at 80 bytes, cut in the middle of A00000000007 $ fold long_record.txt A00000000001 A00000000002 A00000000003 A00000000004 A00000000005 A00000000006 A0 0000000007 A00000000008 A00000000009 A00000000010 # 'fold -s': do not cut in the middle, use available spaces for split $ fold -s long_record.txt A00000000001 A00000000002 A00000000003 A00000000004 A00000000005 A00000000006 A00000000007 A00000000008 A00000000009 A00000000010 # 'fold -w 26` : override default record width 80 $ fold -w26 long_record.txt A00000000001 A00000000002 A00000000003 A00000000004 A00000000005 A00000000006 A00000000007 A00000000008 A00000000009 A00000000010 pr: convert text files for printing The pr command is used to convert files for printing. We can limit the number of lines per page and page width. By default, the command adds timestamp, file name and page number as header. We can override the date format, a title instead of file name using options\nThe print format file created by contains\n 5 line header with header text records formatted based on page width and lines per page 5 line footer with blank lines     Option Description     +M start with page M   +M:N print from page M to N   -l N limit N lines per page   -w N limit page width by N characters   -h TEXT override file name with TEXT in header   -D FMT override date format in header   -t omit header and footer lines; overrides -h    Sample File\n# 'pr -t names.txt': prints same output;  $ cat names.txt 1. alan 2. beth 3. bob ... ... 11. freya 12. felicity 13. gaea Create print format file\n# pr: # -l 8 : 8 lines per page # -w 40 : 40 character page width # Date format: '%d %b %Y'; example 10 Jul 2021 # Title: -h \"Sample Names\" $ pr -l 15 -h \"Sample Names\" -D \"%d %b %Y\" -w 30 names.txt 13 Jul 2021 Sample Names Page 1 1. alan 2. beth 3. bob 4. cathy 5. clive ... ... 13 Jul 2021 Sample Names Page 3 11. freya 12. felicity 13. gaea Summary Though viewing files seem like a simple task as we used to click and open files on the windows environment, we have discussed several commands here that are tailor-made to view files in different way such as viewing sample, as reversed lines, reversed characters.. We will look into these commands again as these will be used in conjunction with other commands to perform tasks such as search, filter, replace and reformating text data and other file manipulation activities such as sort, split, cut, join etc..\n",
    "description": "",
    "tags": null,
    "title": "1.7: Viewing Files",
    "uri": "/part-1/p1-ch6/"
  },
  {
    "content": "Chapter X Warning This topic is Yet to start…\n ",
    "description": "",
    "tags": null,
    "title": "3.6: The \"xargs\" Command",
    "uri": "/part-3/p3-ch6/"
  },
  {
    "content": "Appendix: A Introduction In this chapter, we will group comments by functionality and provide an one-liner explanation to each command. This serves as a reference to the commands we learnt earlier\n This is a simple list of commands with brief explanation. Refer the manual pages of the corresponding commands using man CMD from the shell or online documentation for more information\n  Types of Commands Here we have classified the commands based on the broader functionality these commands provide. This classification is based on the author’s experience with the Linux system as a developer and data analyst. We cover general-purpose commands here with very few system admin commands\n Some commands may fit into multiple categories.\n  Basic commands Files and Directories Access File Permission Viewing Files / Directories Manipulating Files Process and Job Management Text Processing Archival processing Accessing files from remote servers Miscellaneous commands   1. Basic Commands This section covers the basic commands that we will encounter when we start learning the command line interface. These commands are there to get information about the system such as current date, current working directory, clear screen etc..\n These commands gives us a good start to get ourselves comfortable using the shell / CLI\n    # Name Description     1 echo \u003cSTR\u003e print the string on the screen   2 pwd print current working directory   3 date print current date and time   4 clear clear the screen, use the CTRL-L key as alternate   5 sleep \u003cN\u003e sleeps for N seconds   6 cal displays current month’s calendar in tabular format.   7 man CMD displays help text for the CMD passed as argument.   8 history display the list of commands ran so far   9 passwd change password   10 seq create number sequence   11 exit terminate session    2. Files and Directories This section covers commands that are used to create files and access the files. Unix treats everything as files, including hardware devices, network sockets etc.. We will deal with three types of files; regular files such as text and binary files, directories that are containers that can hold other files and links that are shortcuts to actual files and directories\n This set of commands are to create and access files and directories. Next sections have more commands to view and manipulate files and directories\n    # Name Description     1 mkdir create directory   2 cd change directory   3 rmdir remove empty directories, wont work on directories with contents   4 touch create an empty file if it doesn’t exists   5 ln create link to an existing file; can be hard or soft link   6 ls list files and directories   7 tree list a directory and its contents in a tree like format   8 cp copy files and directories   9 mv rename or move files and directories   10 rm remove files and directories with contents   11 unlink remove a file. a simple version of rm to remove one file   12 du display the disk usage info of a file or a directory and its contents   13 df display the free and used space of disks attached to the system    3. File Permissions Everything in Unix is treated as files and every file has explicit permissions associated with it. The permissions determine who can have access to these files and what type of access they have. There are two types of access; Authentication is a way to gain access into the system using credentials and Authorization is how the system determines who have access to what.\nPermissions can be explicitly given when we create directories using mkdir -m \u003cMODE\u003e whre MODE is an octal number representing the permissions. Permissions are given to various actors in the system and files can have different access associated with them. The owner or the super user can perform various actions in terms of providing permissions to various actors.\nActors\n   Name Abbr Description     User u owner of the file   Group g default group the owner belong to   Others o users that are not part of the group   All a every user in the system    Actions\n   Name Abbr Description     Add + add permission   Remove - remove permission   Assign = discard existing permissions and assign new permissions    Access\n   Name Abbr Description     Read r reading from files / viewing contents of directories   Write w writing into files / create, delete files and directories   Execute x execute files (code) / view or modify metadata of files    Permissions can be assigned to user, default group and others as combination the above thre acceses; read, write and execute. The combinations ranging from no permission to all permissions. There are 8 combinations dervived from these three type of access that can be represented in Octal notation. Numbers 4, 2 and 1 are assigned to read, write and execute and the combinations of these access gets the other values 0, 3, 5, 6 and 7.\n   Num Permission Description     0 --- no permission   1 --x execute only   2 -w- write only   3 -wx write and execute   4 r-- read only   5 r-x read and execute   6 rw- read and write   7 rwx read, write and execute     Permissions can be given using the chmod command either by using actors, actions and access notation or using octal notation\n View / Set permission and ownership of files\n   # Name Description     1 umask view or set default permission   2 chmod change permisison on files   3 chown change owner of the file   4 chgrp change group name associated with the file   5 ls view permission info using ls -l option   6 stat view perimssions and other file status such as size, date of creation, …   7 id get info about an user; uid, default group and other groups an user is associated with   8 groups get group info of an user    The below commands will be used by SysAdmins, These are listed here for completeness\n   # Name Description     1 useradd create new user id   2 adduser same as useradd, some installation have this one   3 usermod modify an existing user info   4 userdel delete user   5 groupadd creating new group   6 groupmod modify an existing group info   7 groupdel delete group    4. Viewing Files In the previous section, we have looked into commands that are used to create files and directories and once created how to access and manipulate those files. In this section we will discuss various way in which we can view the files; entire file, part of the file, view page by page,…\n   # Name Description     1 cat view file(s), displayed on the screen   2 tac view file(s), records displayed in reverse order; last record first LIFO. May not be available in some OS versions   3 rev view records in reverse order, like cat but each record is displayed in reverse order   4 nl like cat, adds line number as prefix   5 head display first 10 lines of file(s) by default   6 tail display last 10 lines of file(s) by default   7 less display contents of a file, one line at a time. use spacebar and b to page down and page up and q to quit display   8 more like the less command; older version and limited navigation features   9 od display files as ascii, octal, hexadecimal dump, useful in analyzing binary files   10 wc display number of lines, words and characters of the file(s)    5. Manipulating Data This section deals with commands that can manipulate the contents of files; actions such as sort, slice, split, merge,…\n   # Name Description     1 cut create slices from each record   2 paste merge multiple lines from a file into single line or merge multiple files line by line   3 split split a file into smaller chunks. By default, each split file contains 1000 lines, we can use options to split by different line count or split by bytes size   4 join merge already sorted files by keys, By default it performs an inner or equality join, only display records with matching keys   5 sort sort files, a rich set of options are available   6 uniq create unique records from an already sorted file   7 diff compare two sorted files and display the records that are different   8 column display file in tabular format   9 comm compare two sorted files and display the unique records from file 1, file 2 and matched records in 3 columns. This command is useful to compare files with shorter records   10 cmp compare two files byte by byte and display summary, from which byte/line there is a difference. We can limit the number of bytes to be compared    6. Process Management Unix is a multiuser and multitasking operating system. Processes form the core of the system and they form the logical unit to manage resources needed for each processes. A process is a running instance of a command or a program. Each process needs computing resources such as CPU, memory. When a process is initiated, Unix assigns an unique number called process id also called as PID. We can query the status of running processes and if we specifically want get status of a process, we can use the PID to access it.\nThe Unix family of OS uses a fork() and exec() model to spawn a new process. The processes in Unix forms a tree-like structre. When the system boots up, it launches a process called init that gets the PID 1 and from init other processes are created. Like the root directory in the file system tree structure, init forms the entry to the proccess tree structre. In addition to the PID, the process also has PPID; parent process id that can be used to trace the process hierarchy as needed.\n   # Name Description     1 ps print process status information   2 jobs prints the status of the background processes   3 bg convert a foreground process into background process. Use ^Z to suspend process first   4 fg convert the background process to foreground process.   5 kill forcefully terminate a running job using the PID   6 killall like kill but uses command name. may terminate more than one job   7 nohup submit commands in no hangup mode, job continues to run even if session terminates   8 disown similar to nohup, we simply disown a running job so that it continues to run even if session terminates   9 top view process information in 5 seconds interval. stop command using ^C   10 free displays available, used and free main memory; RAM    Job Schedule We can schedule jobs to run in the future; either once or repeatedly. Unix provides a simple yet elegent syntax to schedule the jobs using combination of minutes, hours, day, month and day of the week.\n   # Name Description     1 crontab schedule jobs   2 at schedule one time jobs   3 atq list jobs scheduled by at   4 atrm remove job(s) scheduled by at    view crontab examples at https://crontab.guru/\n7. Text Processing Unix is very good with process text information. The support for Regular Expressions also called as RegEX makes operations like filter, search, replace easier. In addition to these operations, we have commands to validate, tranform, translate and aggregate information.\n   # Name Description     1 tr translate input stream   2 grep global regular expression and print. search files for patterns and text; supports Basic RegEX (BRE)   3 egrep extended grep, supports Extended RegEX (ERE) syntax. we can also use grep -E instead   4 fgrep fixed grep, search literals, faster than using grep as it doesnt have to validate search string as RegEX. we can also use grep -F instead   5 sed stream editor, search and replace text. A predecessor of the Vi editor   6 awk a programming language that can be used to write code snippets directly on the command line    8. Archival Process This section covers the commands that can be used to compress files to save space and archive multiple files as a single unit. There are commands that can be used to view contents of the files without explicitly uncompressing the files\n   # Name Description     1 zip compress one or more files, ends with .zip extension   2 unzip umcompress one or more files created by the zip command   3 zipinfo get info about the contents of the zip archive   4 gzip compresses a single file using LZ77 coding   5 gunzip uncompress the file created by the gzip command   6 tar create archive files with or without compression   7 gzcat displays content of a .gz file without compressing   8 zgrep grep on .gz file; similar to grep -Z   9 zegrep egrep on .gz file; similar to grep -ZE   10 zfgrep fgrep on .gz file; similar to grep -ZE   11 zipgrep grep on .zip file    9. Remote Access    # Name Description     1 ssh login to remote server   2 scp secure copy from / to local machine and remote server or between two remote servers   3 sftp secure FTP; *File Transfer Protocol'   4 rsync syncronize the contents of directories between local and remote server   5 wget    6 curl     10. Miscellaneous Commands    # Name Description     1 bc calculator   2 dc calculator; expressions in reverse polish notation   3 alias create shortcut to commands or display existing aliases   4 unalias remove an existing alias   5 uname get operating system info; name, processor architecture,…   7 which    8 whatis    9 whereis    10 users get the list of current users.   11 who display all the users who have logged in   12 uptime shows how long the system has been running    11. Advanced Commands    # Name Description     1 find search for files recursively and perform operations on the results   2 xargs build arguments from standard input or redirected output and pass it to a command    ",
    "description": "",
    "tags": null,
    "title": "Commands Summary",
    "uri": "/part-5/p5-ch1/"
  },
  {
    "content": "Appendix: B Shell Special Characters    Character Description     # comment   \\ escape special meaning of the special character and to code escape sequences like tab \\t, newline \\n, etc…   \\n marks end of a command and shell start executing the command(s)   space delimiter of command, options and arguments in a command sequence   \\t same as the space / blank character   $ prefix used in the variable names to get the values referenced by the variables   ! used as a prefix in shortcuts to retrive / reuse previously run commmands and to negate the return code of a command that follows the !       Character Description     * wildcard: represents zero or more characters   ? wildcard: represents zero or one character   […] wildcard: represents characterset   {} brace expansion       Character Description     / represents the root directory and the path separator   ~ represents current user’s home directory       Character Description     ' single qoute; also known as strong quote   \" double qoute; also known as weak quote   ` backtick: treats everyting inside as command, executes and returns the result. This is old style, use $(cmd) instead       Character Description     \u0026 submit command in background mode   ; run multiple commands with ; as delimiter   () submit commands as a sub-process   {} wrap multiple commands together as a block of commands to facilitate output redirection       Character Description     \u003c redirection: input to command from a file   \u003e redirection: output of command to a file   | redirection: output of command to another command. we can chain multiple commands using the |    ",
    "description": "",
    "tags": null,
    "title": "Special Characters",
    "uri": "/part-5/p5-ch2/"
  },
  {
    "content": "Introduction In this chapter, let us discuss ways to manipulate the data from files; operations such as sort, slice, join, reformat, aggregation. etc.. I have originally named this chapter as File Manipulation Commands, however none of the commands discussed here actually change the input file, these commands just manipulate the contents and display the output in stdout that can be redirected into a file.\nThis subset of commands are one of the most frequently used commands and gaining expertise using these commands will be really beneficial to developers, testers and anyone who work with files. Along with the commands used for viewing files, IO Redirection and these data manipulation commands, we can craft command pipelines to extract, reformat and store data in files without writing complex programs.\nSample Files In order to explore the commands, we will use the following 2 files; a fixed format file and a delimited file with same data. Feel free to use these or your own samples with the commands and options specified. A python script to create these files are available at the end of the chapter. In addition to these two files, we will also use few smaller files and the contents of these files will be displayed before being used in the demo.\nstudent.csv\nstudentId,LastName,FirstName,DOB,grade,subject,score,endOfRec S00001,Carlson,Crystal,SOCS,15-May-2013,3,98,Z S00002,Brennan,Angel,MATH,21-Feb-2013,3,74,Z ... ... S00004,Brooks,Jillian,MATH,10-Dec-2010,6,62,Z student.txt\nS00001 Carlson Crystal 15-May-2013 SOCS 03 98 Z S00002 Brennan Angel 21-Feb-2013 MATH 03 74 Z ... ... S00004 Brooks Jillian 10-Dec-2010 MATH 06 62 Z Command List: Data Manipulation    # Name Description     1 cut create slices from each record   2 paste merge multiple lines from a file into single line or merge multiple files line by line   3 split split a file into smaller chunks. By default, each split file contains 1000 lines, we can use options to split by different line count or split by bytes size   4 join merge already sorted files by keys, By default it performs an inner or equality join, only display records with matching keys   5 sort sort files, a rich set of options are available   6 uniq create unique records from an already sorted file   7 tr simple translation and deletion of characters   8 column display file in tabular format   9 colrm remove columns from a file   10 cmp compare two files byte by byte and display summary, from which byte/line there is a difference. We can limit the number of bytes to be compared   11 diff compare two sorted files and display the records that are different   12 comm compare two sorted files and display the unique records from file 1, file 2 and matched records in 3 columns. This command is useful to compare files with shorter records   13 cksum create a checksum and byte count of a given file   14 md5sum create a checksum using MD5 digest algorithm   15 shasum create a checksum using SHA aka Secure Hash Algorithm   16 shuf shuffle records from file    cut : create slices from each record The cut command is used to extract portions of reach record to create a subset of a given file. The subset of records can be created providing column range: col 1-10,25-30,50-end or by fields numbers if we have a delimited file.\nAnother use of the cut command is to convert a delimited file from one-delimiter to another. for example CSV to pipe-delimited file.\n   Option Description     -c column positions to extract   -d CH delimiter to be used; CH should be a single character. used along with -f. default is TAB   -f fields to extract; works with -d for option   -s skip lines if that does not have delimiters. works with -d option   --complement select columns/fields that are not mentioned in -c or -f options   --output-delim use a different delimiter on output records. By default, input delimiter is used    Note: While using -f or -c, we need to provide the individual column positions or field numbers or range or a combination of both. We can use the following conventions\n m-n : column or field from m to n m,n : column or field m and n m- : from m till end of the record  Examples\n -c1-10,25 : columns 1 to 10 and column 25 (11 bytes) -d, -f1-5,10 : fields 1 to 5 and field 10 in a comma-delimited record -c1-10,25,30,40-45,50-: columns 1 to 10, 25, 30, 40 to 45 and 50 till end of record -d, -f1,5,11-15,30-: fields 1, 5, 10 to 15 and from field 30 to the last field in a comma-delimited record  extract last and first names from student.txt\nThe data is in fixed format, each field start at the same column position. Each field has a space in between and each student has 3 records; one per subject - MATH, SCIE and SOCS.\n last name: column 8 to 17, 10 bytes long first name: column 19 to 28, 10 bytes long  # sample data $ head -2 student.txt S00001 Kim Ivan 19-Nov-2012 MATH 04 99 Z S00001 Kim Ivan 19-Nov-2012 SCIE 04 99 Z S00002 Pena Bryan 07-Jun-2013 MATH 03 57 Z $ cut -c8-17,19-28 student.txt Kim Ivan Kim Ivan Pena Bryan ... ... Rosario Emily extract last and first names from student.csv\n# sample data $ head -3 student.csv Id,LastName,FirstName,DOB,grade,subject,score,En S00001,Kim,Ivan,MATH,19-Nov-2012,04,99,Z S00001,Kim,Ivan,SCIE,19-Nov-2012,04,99,Z # delimiter is comma, get fields 2 and 3 $ cut -d, -f2,3 student.csv LastName,FirstName Kim,Ivan Kim,Ivan ... ... Rosario,Emily extract fields other than first and last name\n# --complement: get fields other than listed in '-c' of '-f' $ cut -d, -f2,3 --complement student.csv Id,DOB,grade,subject,score,En S00001,MATH,19-Nov-2012,04,99,Z S00001,SCIE,19-Nov-2012,04,99,Z ... ... S00003,SOCS,21-Apr-2010,06,57,Z convert CSV to pipe-delimited file\n# -f1-: select all fields # --output-delim='|' : set separate output delimiter  $ cut -d, -f1- --output-delim='|' student.csv Id|LastName|FirstName|DOB|grade|subject|score|En S00001|Kim|Ivan|MATH|19-Nov-2012|04|99|Z S00001|Kim|Ivan|SCIE|19-Nov-2012|04|99|Z S00001|Kim|Ivan|SOCS|19-Nov-2012|04|75|Z ... ... S00030|Dewey|Jack|SOCS|21-Apr-2010|06|57|Z convert CSV to TAB delimited file\nThe TAB as output-delimiter works slightly different than any other single-character delimiter. we need to use --output-delim-$'\\t' instead of just \\t.\n# let us skip header  $ tail -n +2 student.csv | cut -d, -f1- --output-delim=$'\\t' S00001 Kim Ivan MATH 19-Nov-2012 04 99 Z ... ... S00003 Rosario Emily SOCS 21-Apr-2010 06 57 Z skip records that does not have delimiters\nSome delimited files will have blank lines at the end along with summary of record count, exported from database tables for example. we can skip the blank records and the summary record using the -s option.\n$ head student.csv Id,LastName,FirstName,DOB,grade,subject,score,En S00001,Kim,Ivan,MATH,19-Nov-2012,04,99,Z ... ... S00100,Newton,Charles,SOCS,26-Jun-2012,04,92,Z 300 record(s) exported from STUDENT table # last 3 records discarded, remove `-s` and try this command $ cut -d, -f1- -s student.csv Id,LastName,FirstName,DOB,grade,subject,score,En S00001,Kim,Ivan,MATH,19-Nov-2012,04,99,Z S00001,Kim,Ivan,SCIE,19-Nov-2012,04,99,Z ... ... S00100,Newton,Charles,SOCS,26-Jun-2012,04,92,Z Note:\nThere might be situations where we need to slice and rearrange columns or fields. The cut command is suitable only for slicing and does not support rearranging columns or fields. We will look into this using another command called awk in the future.\npaste : merge multiple files The paste command typically reads one record from each file, passed as argument and merge the records with a space delimiter and create a single record. If any of these files have less records compared to the other an empty-string is substituted in place.\n   Option Description     -d CH output delimiter, default is TAB   -s paste records as single record from one file at a time, like transpose    Examples\nWe have 2 files cmds.txt that contains the commands list and help.txt that contains the command description. The help.txt has one extra record than the cmds.txt. Let us merge the contents of these two files.\n**Snippet from sample files **\n$ cat cmd.txt echo cat head tail $ cat help.txt display argument on file concatenate files display first 10 records display last 10 records last record has contents from help.txt only\n$ paste cmd.txt help.txt echo display argument on file cat concatenate files head display first 10 records tail display last 10 records paste merge records from files sort files # using delimiter  echo,display argument on file cat,concatenate files head,display first 10 records tail,display last 10 records paste,merge records from files ,sort files Let us say, we have an address file with 3 lines per address and we want to merge the 3 lines into one and create one record per address. We can use paste to merge every 3 records from the address file into single record.\n We need to pass the data as standard input or pipe in order to perform the multiple records merge\n $ head -6 address.py Brooks, Sarah 52848 Cynthia Drives West Jason, MS 82831 Byrd, Kelly 88505 Castro Heights South Vanessa, MA 96024 # single line address as TAB delimited record $ head -9 address.py | paste - - - Brooks, Sarah 52848 Cynthia Drives West Jason, MS 82831 Byrd, Kelly 88505 Castro Heights South Vanessa, MA 96024 # same as above, as comma-delimited record $ head -9 address.py | paste -d, - - - Brooks, Sarah,52848 Cynthia Drives,West Jason, MS 82831 Byrd, Kelly,88505 Castro Heights,South Vanessa, MA 96024 split: split a file into pieces by size or record count The split commands creates smaller chunks from a large file that can be concatenated together to recreate the same file, if needed. In the past, due to the storage size limitations, we may not be able to copy large files in one removable storage devices like floppy, CD,… The split command made such copy possible.\nWe can create smaller file chunks by specifying number of records per file, max file size or even number of chunks we want. By default, the command splits the file by creating chunks of files with 1000 records per file and the last file to have the left over records.\nIn addition to various split options, we can provide file prefix and suffix to be used to name the file chunks. If we do not provide static prefix or suffix, the command will use x as prefix and aa, ab, ac,.. as suffix creating file names xaa, xab, xac,..\nsyntax\n$ split [option(s)] FILE [prefix] common options\n   Option Description     -b N create chunks of N bytes each   -l N create chunks with N records per file   -n N create N files of equal size, may create empty file   -e do not create empty file; used along with -n   -a N suffix length; default is 2: aa, ab, ac, …   -d use numeric suffix increments instead of aa, ab,..   -x use hexadecimal suffix increments instead of aa, ab, ..    other options\n   Option Description     --additional-suffix= provide static suffix   --numeric-suffixes= same as -d, allows starting value   --hex-suffixes= same as -d, allows starting value    examples\nLet us a very large file using the names_v1.txt file and shuf command with -n and -r option. The following command created a 1.4GB file and it may take some time to process. We will also create another file with 7550 records to demo split by record count.\n$ shuf -r -n 123456789 names_v1.txt -o large_file_split_demo.txt $ zip large_file_split_demo large_file_split_demo.txt # file size: 1.4G and 73M respectively $ stat --printf=\"%n: %s\\n\" large_file_split_demo.* large_file_split_demo.txt: 1481481468 large_file_split_demo.zip: 76052943 $ head -7550 large_file_split_demo.txt \u003e split_demo.txt $ wc -l split_demo.txt 7550 split_demo.txt default split\nBy default, the split command creates file chunks with 1000 records per file.\n$ ls large_file_split_demo.txt large_file_split_demo.zip names_v1.txt split_demo.txt # created files with 'x' prefix and 2 byte alpha suffix $ split split_demo.txt $ ls large_file_split_demo.txt names_v1.txt xaa xac xae xag large_file_split_demo.zip split_demo.txt xab xad xaf xah $ wc -l split_demo.txt xaa xab xaf xah 7550 split_demo.txt 1000 xaa 1000 xab 1000 xac 1000 xad 1000 xae 1000 xaf 1000 xag 550 xah max records per file\n$ rm x* # split -l 3000: max records per file is 3000  $ split -l 3000 split_demo.txt $ ls large_file_split_demo.txt names_v1.txt split_fileaa split_fileac xab large_file_split_demo.zip split_demo.txt xaa xab xac $ wc -l xa* 3000 xaa 3000 xab 1550 xac 7550 total using prefix / suffix for output files\n# pass prefix as the second argument: 'split_file_'  $ split -l 3000 split_demo.txt split_file_ $ wc -l split_file_* 3000 split_file_aa 3000 split_file_ab 1550 split_file_ac 7550 total # add suffix $ split -l 3000 split_demo.txt split_file_ --additional-suffix=\"_chunk.txt\" $ wc -l *chunk* 3000 split_file_aa_chunk.txt 3000 split_file_ab_chunk.txt 1550 split_file_ac_chunk.txt split into N files\nWe can use the -n NUM option to specify how may chunks we want to create.\n$ split -n 4 split_demo.txt split_file_ --additional-suffix=\"_chunk.txt\" $ wc -l *chunk* 1887 split_file_aa_chunk.txt 1888 split_file_ab_chunk.txt 1887 split_file_ac_chunk.txt 1888 split_file_ad_chunk.txt split by size\nLet us use the -b N option to create files of max N Bytes size, We can suffix K, M, G, T to specify size in KB, MB, etc.. For this demo, we will use the 73 MB zip file.\nWe will use the -d N to use numeric suffix instead of alphabetic and -a N option to provide suffix size instead of default 2 bytes. The numeric suffix starts with 0 and incremented by 1 when we use the -d option. If we need the suffix to start with some other number, we can use the --numeric-suffixes=NNN option.\ncheck the zip file details\n$ ls -lh large_file_split_demo.zip -rw-r--r-- 1 mktutes mktutes 73M Aug 11 05:52 large_file_split_demo.zip # zipinfo: provides info about the zipped files # like the ls -l command $ zipinfo large_file_split_demo.zip Archive: large_file_split_demo.zip Zip file size: 76052943 bytes, number of entries: 1 -rw-r--r-- 3.0 unx 1481481468 tx defN 21-Aug-11 05:49 large_file_split_demo.txt 1 file, 1481481468 bytes uncompressed, 76052743 bytes compressed: 94.9% split the files by 10MB chunk\n# use numeric suffix of 5 bytes long # output file prefix is \"num_\" $ split -d -a 5 -b 10M large_file_split_demo.zip num_ $ ls -lh num_* -rw-r--r-- 1 mktutes mktutes 10M Aug 11 07:56 num_00000 -rw-r--r-- 1 mktutes mktutes 10M Aug 11 07:56 num_00001 -rw-r--r-- 1 mktutes mktutes 10M Aug 11 07:56 num_00002 -rw-r--r-- 1 mktutes mktutes 10M Aug 11 07:56 num_00003 -rw-r--r-- 1 mktutes mktutes 10M Aug 11 07:56 num_00004 -rw-r--r-- 1 mktutes mktutes 10M Aug 11 07:56 num_00005 -rw-r--r-- 1 mktutes mktutes 10M Aug 11 07:56 num_00006 -rw-r--r-- 1 mktutes mktutes 2.6M Aug 11 07:56 num_00007 concat file chunks and check the integrity of the zip file\n$ cat num_0000* \u003e temp.zip $ ls -lh temp.zip -rw-r--r-- 1 mktutes mktutes 73M Aug 11 07:59 temp.zip $ md5sum *.zip a6d0061a44673d9493f238850eb20c5a large_file_split_demo.zip a6d0061a44673d9493f238850eb20c5a temp.zip $ zipinfo temp.zip Archive: temp.zip Zip file size: 76052943 bytes, number of entries: 1 -rw-r--r-- 3.0 unx 1481481468 tx defN 21-Aug-11 05:49 large_file_split_demo.txt 1 file, 1481481468 bytes uncompressed, 76052743 bytes compressed: 94.9% join: merge two sorted files using a key The join command merges two lexically sorted by a common field. By default, it merges the matched records from both files. We can also write unmatched records from one or both files using additional options. By default, the output will have the join key followed by remaining fields from FILE1 and then FILE2.\nThe command uses space as default field delimiter and considers the first field as a key for comparison. We can override the delimiter and specify different field numbers as comparison key.\nThe join command works similar to the JOIN operation of SQL queries. However it only uses a single field for matching.\n   Option Description     -a 1 print unmatched key and data from FILE1; left outer join   -a 2 print unmatched key and data from FILE2; right outer join    -a 1 -a 2 : prints unmatched records from both files; full outer join   -v 1 suppress matched records from FILE 1   -v 2 suppress matched records from FILE 2    -v 1 -v 2: suppress matched records from both files   -t -t CH:use CH as input field delimiter instead of space   -i ignore case while comparing fields; sort using -f option   -j N use FIELD N from FILE 1 and 2 for comparison instead of first field   -1 N use FIELD N from FILE 1 for comparison   -2 N use FIELD N from FILE 2 for comparison   -e STR print STR against missing values    we need to use -o auto along with -a and -e   -o FMT override default merge order    -o 0 to display on the keys. -o 1.2 2.2 to display individual fields    use FILENUM.FIELDNUM,... to rearrange fields   --header treat first line as header    sample files\nFor this demo, let us create two files with numbers in ascending order as first field. The roman numeral and numbers spelling as second fields on file one and two respectively. These files are named roman.txt and english.txt.\nWe will use --header option to treat the first record from both files as header.\n$ cat roman.txt NBR Roman 1 I 2 II 3 III 4 IV 5 V $ cat english.txt NUM Text 0 Zero 1 One 2 Two 3 Three 4 Four inner join: also known as natural join (default)\nThe join command without any options merges the two files using first field delimited by spaces and output the matched records from both files. The unmatched records from both files will be skipped. In this example, last record; 5 V from roman.txt and first record; 0 Zero from english.txt will be skipped.\n$ join --header roman.txt english.txt NBR Roman Text 1 I One 2 II Two 3 III Three 4 IV Four **left outer join: print matched records and unmatched from FILE 1\nThe -a 1 option prints the unmatched record from FILE 1 along with the matched records. By default, the unmatched records will not have any data for the FILE 2 columns. If we want to print default values, we need to use the -e VAL and -o auto options.\n$ join --header -a 1 roman.txt english.txt NBR Roman Text 1 I One 2 II Two 3 III Three 4 IV Four 5 V # print NA for missing values; see record: `5 V NA` $ join --header -a 1 -e NA -o auto roman.txt english.txt NBR Roman Text 1 I One 2 II Two 3 III Three 4 IV Four 5 V NA **right outer join: print matched records and unmatched from FILE 2\nThe -a 2 option prints matched records and unmatched records from FILE 2. Missing values from FILE 1 against the unmatched records will display NA. Look at record 0 NA Zero.\n$ join --header -a 2 -e NA -o auto roman.txt english.txt NBR Roman Text 0 NA Zero 1 I One 2 II Two 3 III Three 4 IV Four full outer join: print matched and unmatched records from both files\n$ join --header -a 1 -a 2 -e NA -o auto roman.txt english.txt NBR Roman Text 0 NA Zero 1 I One 2 II Two 3 III Three 4 IV Four 5 V NA extract unmatched records only\nSometimes, we might be interested in missing records; for example, if we run a same code twice with expectations that we should get same number of records with matching fields. We can verify this expectation by running the join command with no options. If the record count of both files are same and the count of output records matches with input count then our expectation is met. However if we see differences in record counts between input files or input and output, we need to know which keys did not match between the two files.\nWe can use the -v N option to suppress the matched records and -a N to display the unmatched records from FILE N (N=1 or 2). We can get the unmatched records from one of the files or both files. Furthermore, if we are just interested in only the keys, we can display the keys alone using the -o option.\n# join: # --header: treat first record as header and use if for display # -v 1 : suppress matching records # -a 1 : display unmatched records from FILE 1 # -o 0 : display only the keys $ join --header -v 1 -a 1 -o 0 roman.txt english.txt NBR 5 # unmatched records from FILE 2: -v 2 -a 2 $ join --header -v 2 -a 2 -o 0 roman.txt english.txt NBR 0 # unmatched records from both files $ join --header -v 2 -a 2 -a 1 -o 0 roman.txt english.txt NBR 0 5 override input field delimiter and specify matching field numbers\nIf the files we use in join has a different delimiter, then we can use the -t CHAR to override the default delimiter (space). Both input files should have the same delimiter.\nLet us create a roman.csv file as a comma-delimited file and swap field 1 and 2. Let us also create another file called num_string.csv with numbers spelt in English, German as field 1 and 2 and matching field (arabic numerals) as field 3.\n$ head -2 roman.csv Roman,NBR I,1 $ head -2 num_string.csv English,German,NUM Zero,Null,0 # join -t: input delim, -1 N and -2 N : matching field numbers $ join --header -t, -1 2 -2 3 roman.csv num_string.csv NBR,Roman,English,German 1,I,One,Eins 2,II,Two,Zwei 3,III,Three,Drei 4,IV,Four,Vier reorder output fields\nIn the above example, the output of join will be formatted as follows; key, fields from file 1 followed by fields from file 2. This can be overridden using the -o option where 0 represents the key field and FILE_NBR:FIELD_NBR to specify the individual fields. For example -o 0 1.2 2.1 is to print key followed by 2nd field from file 1 and 1st field from file 2.\n$ $ join --header -t, -1 2 -2 3 -o \"0 2.1 1.1 2.2\" roman.csv num_string.csv NBR,English,Roman,German 1,One,I,Eins 2,Two,II,Zwei 3,Three,III,Drei 4,Four,IV,Vier case-insensitive comparison\nWhen join compares the matching fields, it does a case-sensitive comparison, that makes the uppercase and lowercase letters as distinct entities. Sometimes, we may not care about the case of the alphabets in the key. We can use the -i option to enable case-insensitive comparison.\n If we use -i, the files have to be sorted by keeping uppercase and lowercase values together. See the -f option in sort command in the next section for more info.\n  The matching key will be from the first file passed as argument to the join command\n For the case-insensitive comparison, let use replace the numbers with alphabets; uppercase in one file and lowercase in another file and create a new set of files.\n$ head -3 alpha_roman.txt NBR Roman b II c III $ head -3 alpha_num.txt NUM Text A One B Two # inner join: no matches due to case difference $ join --header alpha_roman.txt alpha_num.txt NBR Roman Text # key will be taken from file 1 $ join --header -i alpha_roman.txt alpha_num.txt NBR Roman Text b II Two c III Three d IV Four $ join --header -i alpha_num.txt alpha_roman.txt NUM Text Roman B Two II C Three III D Four IV sort: sort a file Some of the commands we discussed so far; uniq and join and few more commands that we will discuss later; file comparison commands for example expect the input file(s) to be sorted. Understanding how the sort command works is very important and gaining expertise in using the command is very important for anyone who want to gain expertise using the CLI.\nThe sort command by default, sorts the records starting from column 1 all the way to the last column. It uses the ASCII value of the characters on a given column to decide the order in which the records to be sorted. For example, uppercase A will be sorted before lowercase a because of their ASCII values; 65 and 97 respectively. The records are sorted in ascending order by default.\nThe sort command comes with an extensive collection options to control how the records within a file will be sorted. We will look at the commonly used options and once we become familiar with these options, we can focus on other options.\nHere are the sorting options\n   Option Description     -d dictionary order; consider blanks and alphanumeric characters only   -n numeric sort; instead of column-by-column comparison, treat a sequence of numbers as single entity for sorting   -h human-readable sorting on byte size; 10K, 2M, 1G etc..   -M month sort; JAN, FEB, MAR, etc…   -k specify field numbers / column position as sort keys   -f case-insensitive sort    some versions of sort does case-insensitive sort by default   -r sort in descending order; reverse sort   -R random sort; shuffle the records but keep sort keys of same value together   -m merge already sorted files together   -u unique sort; keep only the first occurrence of record based on the sort key    Here are some options to override the default configuration settings.\n   Option Description     -t CH override default field separator (space) with CH   -T DIR override default temp directory used (/tmp)   -o FILE write sorted output to FILE   -c check whether a file is already sorted or not    error message if not sorted   -C same as -c but suppress the error message    use echo $? to check; 0=OK, 1=Not OK    sort a names file: case-sensitive and case-insensitive\nSorting of alphabets is usually case-sensitive, that is uppercase alphabets are sorted before the lowercase due to their ASCII values; uppercase alphabets have smaller ASCII value compared to the lowercase alphabets. We can use the -f option to perform a case-insensitive sort.\n Depending on the sort command version, the case-insensitive comparison may be done by default. sort command in google cloud shell does an case-insensitive sort whereas sort command in Macbook does a case-sensitive sort.\n $ cat names.txt Macias gerald Huang Gordon diana Daugherty Cook # mac os: case-sensitive sort by default $ sort names.txt Cook Daugherty Gordon Huang Macias diana gerald # google cloud shell: case-insensitive sort by default $ sort names.txt Cook Daugherty diana gerald Gordon Huang Macias If we want to sort case-sensitive explicitly, we can set the LOCALE environment variable as LC_ALL=C.\n# case-sensitive sort: setting LC_ALL=C env variable # LC_ALL: Language LOCALE settings # uppercase before lowercase $ LC_ALL=C sort names.txt Cook Daugherty Gordon HuangMacias diana gerald # case-insensitive sort $ LC_ALL=C sort -f names.txt reverse sort using -r\nBy default, the records are sorted in ascending order and we can use -r to reverse sort in descending order.\n# reverse sort along with case-fold / case-insensitive sort $ sort -f -r names.txt Macias Huang Gordon gerald diana Daugherty Cook numeric sort\nBy default, sort performs an ASCII sort, comparing the ASCII value of the characters in each column to arrange the records in ascending order. If two records have same value in a given column, sort moves to the next column and performs the comparison.\nThe -n option overrides this behaviour and forces sort to treat consecutive numbers separated; a field to be treated as a whole in numeric form rather than sequence of characters. Let us sort a file with random number and see how the -n impacts the way sorting occurs.\n$ cat rand_nums.txt 22675 81 91 ... .. 3 9 8634 default sort; column wise sort that grouped all 1 together at column 1 and sorted ascending on column 2, …\n$ sort rand_nums.txt 116 151400 199 22057 22675 3 3149 81 8634 88 9 91 numeric sort: set of characters treated as numbers\n$ sort -n rand_nums.txt 3 9 81 88 91 116 199 3149 8634 22057 22675 151400 sorting human-readable file size: KB, MB, GB, TB, …\nIn order to sort by file-size displayed in human-readable form, sort provides -h option. If we use the ls option to display the file list by size, we can use ls -lSh or ls -lShr to apply sort in the command itself. Sometimes, we may get the details as a report or a file. In that case, we will use -h along with other commands like cut to extract file name and size to sort by file size.\n$ sort rand_file_size.txt 1G 1T 20K 2G 2K 2M 3.4K 987 $ sort -h rand_file_size.txt 987 2K 3.4K 20K 2M 1G 2G 1T sort using portion of a file\nThe sort command has the -k or --key=KEYDEF option to sort the file using parts of the records. If it is fixed-format file, we can use start and end column numbers. For delimited files, we can specify the delimiter using -t and list the field numbers by which we want the file to be sorted. We can specify more one set of keys.\nThe -k accepts argument FIELD_NBR.COL_POS with optional sort type like h, n that will be local to the specific key alone. For example -k1.9,1.12n -k1.1,1.5 means perform a numeric sort using columns 9-12 then sort by columns 1-5. For the fixed format files the FIELD_NBR is always 1.\nFor the delimited files, we can use the field numbers and optionally column numbers within the field itself. For example, -k2 -k5n -k1 means sort by the second field, fifth field numerically and the first field. -k2.6,2.10 means sort by the second field but consider only the column 6-10 from field 2.\nHere is the student file we have used in cut demo. Let us sort the file with following criteria\n grade: field 6 score: field 7 numeric sort, reverse data-of birth: year, month date - key and month sort Last Name First Name  $ cat student_math.csv S00001,Huang,Amanda,30-NOV-2010,MATH,06,58,Z S00002,Sherman,Cody,23-MAY-2009,MATH,07,89,Z S00003,Gordon,Heidi,09-NOV-2009,MATH,07,87,Z S00004,Gomez,Kelly,29-APR-2010,MATH,06,92,Z S00005,Cook,Lisa,28-SEP-2011,MATH,05,83,Z S00006,Daugherty,Joshua,05-APR-2011,MATH,05,94,Z S00007,Macias,Emma,21-SEP-2009,MATH,07,79,Z Here is the command with options to perform different types of sorting supported by the sort command; numeric, reverse, month, keys etc.. You may create your own file with duplicate values for any of these fields and try it out for better understanding.\n# -t, : comma-delimited file # -k6,6 : #6 is grade # -k7,7rn : #7 is score; numeric and descending # -k4.8,4.11 : #4 is DOB, sort by year @pos 8-11 of field 4 # -k4.4,4.6M : sort by Month in 'MMM' using '-m' option # -k4.1,4.2 : sort by date # -k2,2 -k3.3: last name and first name  $ sort -t, -k6,6 -k7,7rn -k4.8,4.11 -k4.4,4.6M -k4.1,4.2 -k2,2 -k3.3 student_math.csv S00082,Ross,Scott,05-FEB-2010,MATH,06,85,Z S00017,Stone,James,30-MAR-2010,MATH,06,84,Z S00041,Rush,Kristina,14-AUG-2010,MATH,06,84,Z S00078,Golden,Valerie,10-JAN-2010,MATH,06,83,Z S00058,Ayala,Keith,29-FEB-2010,MATH,06,83,Z uniq: get unique values, counts from “sorted” data The uniq command at its simplest form will display unique values by removing the duplicate entries. In order for the command to work, the input should be in sorted order. Using additional options, the uniq command can\n return the one occurrence of entries that has duplicates return all the duplicates, not just one entries count the number of occurrences of each entry     Option Description     -u return entries that does not have any duplicates   -d return one occurrence per entry that has duplicates   -D return all occurrences of entries with duplicates   -c count the number of occurrences of each entry    less commonly used options:\nThese options can home in handy if we need to check uniqueness only on part of record. We can skip first N bytes or fields not in the middle, I have documented these options for awareness and if interested, please explore on your own\n   Option Description     -i ignore case while comparing   -f N skip N fields (separated by spaces or TAB)   -s N skip N characters from the start for comparison   -w N consider only N characters for comparison    get uniq subject list from student.txt\nThe subject code is 4 bytes long string starting at position 42. Here are the steps\n extract the subject code using the cut command sort the data extract from cut pass it to uniq  $ head -3 student.txt S00001 Kim Ivan 19-Nov-2012 MATH 04 99 Z S00001 Kim Ivan 19-Nov-2012 SCIE 04 99 Z S00001 Kim Ivan 19-Nov-2012 SOCS 04 88 Z # get subject list $ cut -c42-45 student.txt | sort | uniq MATH SCIE SOCS get number of records by grade from student.txt\nThe grade is 2 bytes long string starting at position 47. Here are the steps\n extract the grade using cut command sort the grades pass it to uniq with -c option the results will be displayed as COUNTS GRADE  # grade 03 has 51 records, ... $ cut -c47-48 student.txt | sort | uniq -c 51 03 60 04 60 05 72 06 57 07 find students with same last name\nThe student.txt file has multiple records per student; one per subject that needs additional command pipeline. Here are the steps\n extract student id, last name and first name using cut sort the results and get uniq combination of these 3 fields extract last name using cut sort the last names pass the sorted last names to uniq with -d option  $ cut -c1-28 student.txt | sort | uniq | cut -c8-17 | sort | uniq -d Evans Hernandez Jones May Miller Rivera Ward # The file has 2 students with same last name: WARD S00065 Ward Daniel S00093 Ward Marcus find students with uniq and duplicate last names\nWe need to do the same steps from the previous example except for the last step. We will add two more commands to cut -c1-28 student.txt | sort | uniq | cut -c8-17 | sort\n for students with unique last names, we will use uniq -u for students with shared last names, we will use uniq -D since these two may produce a long list, we will pipe the results to wc -l to just get the count we can verify the counts against the unique students on the original file and compare it with the sum of uniq + shared last name counts  # get count of students with unique last name $ cut -c1-28 student.txt | sort | uniq | cut -c8-17 | sort | uniq -u | wc -l 84 # get counts of students with shared last names $ cut -c1-28 student.txt | sort | uniq | cut -c8-17 | sort | uniq -D | wc -l 16 # get record counts of student.txt $ cut -c1-28 student.txt | sort | uniq | wc -l 100 # 100 == 84 + 16 ---\u003e MATCHES !!! tr: substitute, delete or squeeze characters The tr command is an abbreviation for translate is used to perform data manipulation at individual character level. We can do the following using tr\n substitute one character with another delete a set of characters delete everything other than a given set of characters squeeze or remote duplicate characters that are next to each other   The tr command accepts input from stdin or pipe only\n    Option Description     -d SET delete from input all the characters from SET   -c complement, when used with -d as -dc SET, it deletes all the characters that are not in SET   -s SET remove duplicates of all characters in SET that are next to each other   -t SET1 SET2 while substituting characters from SET1 by SET2, truncate SET1 to match the length of SET2    convert uppercase to lowercase\n$ echo \"HELLO World\" | tr 'A-Z' 'a-z' hello world $ echo \"HELLO World\" | tr [[:upper:]] [[:lower:]] hello world substitution cipher: ROT13\nThe tr command can be used to create simple ciphers by substituting one character with another. This is also called as caesar cipher as it was reportedly used by Julius Caesar himself. The ROT13 is a special case of caesar cipher that shifts the character position by 13; a by n, b by o,.. We can use tr to create ciphers like this.\nNote: The substituted text will revert itself if we process the text with the tr command that created it in the first place. This can be cracked with repeated attempts using the tr command itself.\n$ echo \"Hello World\" | tr 'A-Za-z' 'N-ZA-Mn-za-m' Uryyb Jbeyq # translate to lowercase first and create cipher $ echo \"Hello World\" | tr 'A-Z' 'a-z' | tr 'a-z' 'n-za-m' uryyb jbeyq # get the original text back $ echo \"uryyb jbeyq\" | tr 'a-z' 'n-za-m' hello world $ echo \"hello world\" | tr 'a-z' 'n-za-m' | tr 'a-z' 'n-za-m' hello world The character sets used, a-z and n-za-m should be of same length and here a-z means starting from ASCII value of a to z that is 26 lowercase alphabets and n-za-m also has same 26 alphabets.\nWhat happens if we have less characters in SET1 than SET2? The extract characters will be discarded and it will not have any impact. On the other hand, if we have more characters in SET1 compared to SET2, the last character in SET2 will be repeated to match the length of SET1.\nFor example tr 'aeiou' 'AE' will be treated as tr 'aeiou' 'AEEEE'. If we do not want the default behaviour then we can use the -t flag that truncates the excess characters in SET1. For example tr -t 'aeiou' 'AE' will be treated as tr -t'ae' 'AE'.\n$ echo \"education\" | tr 'aeiou' 'AE' EdEcAtEEn $ echo \"education\" | tr -t 'aeiou' 'AE' EducAtion # use case: replace all numbers with * $ echo 'Current Salary is \"65000.00 USD\"' | tr '0-9' '*' Current Salary is \"*****.** USD\" delete characters\nThe -d SET option removes all the characters from SET whereas the -d -c SET will remove all the characters that are not in SET.\n$ echo \"education\" | tr -d 'aeiou' dctn $ echo \"education\" | tr -dc 'aeiou' euaio squeeze characters The -s SET option removes the duplicate characters when they are repeated. we can use it to remove extra spaces in sentences for example.\n$ echo \"hello world\" hello world $ echo \"hello world\" | tr -s ' ' hello world column: format data in tabular form The column command is very useful if we want out output to be formatted as column-oriented or tabular output. This comes handy while viewing delimited files as each field may be of different length, viewing and understanding the data may pose difficulties\n   Option Description     -s SET set of delimiters to be used to split record to fields   -t determine the number of columns in the input first    pretty print CSV file in tabular format\n$ head -5 student.csv | cut -d, -f1-7 Id,LastName,FirstName,DOB,grade,subject,score S00001,Kim,Ivan,MATH,19-Nov-2012,04,99 S00001,Kim,Ivan,SCIE,19-Nov-2012,04,99 S00001,Kim,Ivan,SOCS,19-Nov-2012,04,88 S00002,Pena,Bryan,MATH,07-Jun-2013,03,57 $ head -5 student.csv | cut -d, -f1-7 | column -s, -t Id LastName FirstName DOB grade subject score S00001 Kim Ivan MATH 19-Nov-2012 04 99 S00001 Kim Ivan SCIE 19-Nov-2012 04 99 S00001 Kim Ivan SOCS 19-Nov-2012 04 88 S00002 Pena Bryan MATH 07-Jun-2013 03 57 colrm: remove columns from file and print This is a simpler version of the cut command the remove columns based on the start and stop index provided as argument. If only one number is provided, it will be considered as stop index and the command displays record from column 1 to one column before the index. If both start and stop indices are provided then the command removes the columns from start to the stop. The command accepts a file or input from stdin for processing\n The index starts with 1 not 0\n  We can just remove one set of contiguous columns\n using fixed format text file\n# sample file $ head -5 student.txt S00001 Huang Amanda 30-Nov-2010 MATH 06 58 Z S00002 Sherman Cody 23-May-2009 MATH 07 89 Z S00003 Gordon Heidi 09-Nov-2009 MATH 07 87 Z S00004 Gomez Kelly 29-Apr-2010 MATH 06 92 Z S00005 Cook Lisa 28-Sep-2011 MATH 05 83 Z # get student id, last and first name # extract col 1-29 $ head -5 student.txt | colrm 30 S00001 Huang Amanda S00002 Sherman Cody S00003 Gordon Heidi S00004 Gomez Kelly S00005 Cook Lisa # discard data of birth and display other columns $ head -5 student.txt | colrm 30 41 S00001 Huang Amanda MATH 06 58 Z S00002 Sherman Cody MATH 07 89 Z S00003 Gordon Heidi MATH 07 87 Z S00004 Gomez Kelly MATH 06 92 Z S00005 Cook Lisa MATH 05 83 Z using STDIN\n# get column 1-4 alone $ echo 'abcdefghijklm' | colrm 5 abcd # remove column 5-8: efgh $ echo 'abcdefghijklm' | colrm 5 8 abcdijklm # same as above; using cut command $ echo 'abcdefghijklm' | cut -c5-8 --complement abcdijklm cmp: compare two files byte by byte cmp is one of the 3 file comparison command we will discuss in this chapter. This is the simplest command of the 3 that compares two files byte-by-byte. If both files are same, it displays nothing otherwise a message that says files differ at byte N, Line N.\n cmp command display the line number and the position where the difference starts.\n The command sets return code 0 if both files are same, 1 if there is any difference and 2 if there are any issues with the argument or options. Use the echo $? command after running cmp to display the return code.\n   Option Description     -i N skip N bytes from both files before comparison   -i M:N skip M bytes from FILE 1 and    N bytes from FILE 2 before comparison   -n N consider only N bytes for comparison   -s suppresses normal output;    error messages will still be displayed.    use echo $? to find the status of comparison   -l verbose displays byte at which the command found the difference    and the value at byte number from both files     cmp is one of the rare commands that DOES NOT use -v for turning on verbosity. It uses -l instead. -v is used to display the version of the cmp command\n Examples:\nsample files\n$ cat cmp_demo_01.txt NumBERS: 0123456789X $ cat cmp_demo_02.txt Numbers: 0123 5 7 X $ cat cmp_demo_03.txt NUMS: 0123456789X basic comparison\n# compare as it is # difference at byte 4 of line 1; 'B' in file 1 and 'b' in file 2 $ cmp cmp_demo_01.txt cmp_demo_02.txt cmp_demo_01.txt cmp_demo_02.txt differ: byte 4, line 1 # -i 8: skip first 8 bytes from both files # 14th byte has '3' in file 1 and ' ' in file 2 $ cmp -i 8 cmp_demo_01.txt cmp_demo_02.txt cmp_demo_01.txt cmp_demo_02.txt differ: byte 6, line 1 # same command but in silent mode # use 'echo $?' to display return code $ cmp -i 8 -s cmp_demo_01.txt cmp_demo_02.txt # rc: 0=files are same, 1=files are different $ echo $? 1 # -n 5: compare only 5 bytes after skipping first 8 bytes # 5 bytes match  $ cmp -i 8 -n 5 cmp_demo_01.txt cmp_demo_02.txt $ echo $? 0 more comparison\n$ cat cmp_demo_01.txt cmp_demo_03.txt NumBERS: 0123456789X NUMS: 0123456789X # -i M:N : skip M bytes from file 1 and N bytes from file 2 # skip \"NumBER\" from file 1 and \"NUM\" from file 2 $ cmp -i 6:3 cmp_demo_01.txt cmp_demo_03.txt # matched $ echo $? 0 The -l option provides the byte numbers where there are difference and the value from both files. The example below has 6 64 40. This means at byte 6, file 1 has 64 and 40 as internal representation of 4 and spaces. This is not exactly the ASCII value. For more info, look at Little and Big Endian representation of data\n# -l: verbose # skip some bytes and compare files # the command compares \"0123456789X\" and \"0123 5 7 X\" $ cmp -i8 -l cmp_demo_01.txt cmp_demo_02.txt 6 64 40 8 66 40 10 70 40 11 71 40 diff: compare files line by line The diff command is much more sophisticated than the command. It compares two files line-by-line and display the lines that are different. For better comparison, both files should be sorted. There is a diff3 command like diff but it compares 3 files instead of 2.\nThe command sets return code 0, if both files are identical and 1 if there are differences. We can use the echo $? command to display the return code after running the diff command.\n Note: The output of the diff command can be used with another command called patch to merge the differences between the two files and update the original file. Discussion on patch is beyond the scope.\n    Option Description     -s display a message when both files are identical; prints nothing by default   -q display a message when both files differ instead of printing the actual differences   -i ignore case of alphabets during comparison   -N treat file not found as empty file   -b ignore whitespaces   -y print the differences side-by-side; we can use sdiff instead of diff -y    Other option(s)\n--suppress-common-lines can be used with -y to suppress matching records\nExamples:\nBoth files has same contents except few records that has all uppercase. File 2 has one extra record\n$ cat student_file_v1.txt S00001 HUANG AMANDA 30-NOV-2010 MATH 06 58 Z S00002 Sherman Cody 23-May-2009 MATH 07 89 Z S00003 Gordon Heidi 09-Nov-2009 MATH 07 87 Z S00004 GOMEZ KELLY 29-APR-2010 MATH 06 92 Z S00005 Cook Lisa 28-Sep-2011 MATH 05 83 Z S00006 Daugherty Joshua 05-Apr-2011 MATH 05 94 Z S00007 MACIAS EMMA 21-SEP-2009 MATH 07 79 Z $ cat student_file_v2.txt S00001 Huang Amanda 30-Nov-2010 MATH 06 58 Z S00002 Sherman Cody 23-May-2009 MATH 07 89 Z S00003 Gordon Heidi 09-Nov-2009 MATH 07 87 Z S00004 Gomez Kelly 29-Apr-2010 MATH 06 92 Z S00005 Cook Lisa 28-Sep-2011 MATH 05 83 Z S00006 Daugherty Joshua 05-Apr-2011 MATH 05 94 Z S00007 Macias Emma 21-Sep-2009 MATH 07 79 Z S00008 Molina William 21-Sep-2011 MATH 05 57 Z $ cp -v student_file_v2.txt student_file_v2.txt.bk 'student_file_v2.txt' -\u003e 'student_file_v2.txt.bk' diff without any options\nBy default, diff performs a case-sensitive comparison and displays records that are different. In this case records 1, 4 and 7 are different.\n Records with difference from FILE 1 are prefixed with \u003c and FILE 2 are prefixed with \u003e. The --- is a placeholder to indicate that there are matched records in between.\n $ diff student_file_v1.txt student_file_v2.txt 1c1 \u003c S00001 HUANG AMANDA 30-NOV-2010 MATH 06 58 Z --- \u003e S00001 Huang Amanda 30-Nov-2010 MATH 06 58 Z 4c4 \u003c S00004 GOMEZ KELLY 29-APR-2010 MATH 06 92 Z --- \u003e S00004 Gomez Kelly 29-Apr-2010 MATH 06 92 Z 7c7 \u003c S00007 MACIAS EMMA 21-SEP-2009 MATH 07 79 Z --- \u003e S00007 Macias Emma 21-Sep-2009 MATH 07 79 Z \u003e S00008 Molina William 21-Sep-2011 MATH 05 57 Z diff -q: display a message if both files are different\nBy default diff prints the differences between two files. If we are not concerned about the actual differences, we can use the -q option to print a message when there are differences.\n$ diff -q student_file_v1.txt student_file_v2.txt Files student_file_v1.txt and student_file_v2.txt differ $ echo $? 1 diff -s: display a message if both files are identical\n# no output if files are identical: default $ diff student_file_v2.txt student_file_v2.txt.bk # -s: display a message if both files are identical $ diff -s student_file_v2.txt student_file_v2.txt.bk Files student_file_v2.txt and student_file_v2.txt.bk are identical Discard the output and inspect $?\nThe -s and -q commands display the status as message when the files are identical and different respectively. However since we will not know in advance whether the files are going to match or not. If we do not need the actual differences, we can redirect the output of the diff command to /dev/null, a special device file that acts like a Recycle Bin. We call it as bitbucket or black hole\n# discard differences  $ diff student_file_v1.txt student_file_v2.txt \u003e /dev/null # echo $?: 0=identical, 1=differences $ echo $? 1 # compare original and backup; no messages if files are identical $ diff student_file_v2.txt student_file_v2.txt.bk # echo $?: 0=identical, 1=differences $ echo $? 0 diff -i: case-insensitive comparison\nThe first example we saw, the diff command without any option performs a case-sensitive comparison. At times, the only difference between two files might be the case of the alphabet. For example, version 1 of the file might have names in title case and version 2 of the file is changed to have names in uppercase. If we want to compare these files and find out the real differences such as extra or missing records or differences in fields, we can use the -i option to perform a case-insensitive comparison.\n# records 1, 4 and 7 matched with -i option $ diff -i student_file_v1.txt student_file_v2.txt 7a8 \u003e S00008 Molina William 21-Sep-2011 MATH 05 57 Z diff -N: Dealing with File Not Found issues\nBy default, if one of the file passed as argument is non-existing, the diff command displays an error message and set return code 2. The -N option instructs diff to treat non-existent file as an empty files.\n$ diff student_file_v4.txt student_file_v1.txt diff: student_file_v4.txt: No such file or directory $ diff -N student_file_v4.txt student_file_v1.txt 0a1,7 \u003e S00001 HUANG AMANDA 30-NOV-2010 MATH 06 58 Z \u003e S00002 Sherman Cody 23-May-2009 MATH 07 89 Z diff -b: Dealing with leading and trailing blanks\nLet us extract the last names from the student_file_v*.txt and compare the files. We will cut 10 bytes from one file and 11 bytes from another file and run diff with and without -b option.\n# add an empty line and extract last names from v1 file $ cut -c8-18 student_file_v1.txt \u003e names_v1.txt # extract last names from v1 file and add an empty line $ cut -c8-17 student_file_v2.txt \u003e names_v2.txt # display one record from each file and show newline as $ $ head -1 names_v* | cat -E ==\u003e names_v1.txt \u003c==$ HUANG $ ==\u003e names_v2.txt \u003c==$ Huang $ # compare case-insensitive and ignore leading/trailing blanks # one extra record \"Molina\" in file 2 and  # one blank rec each $ diff -bi names_v1.txt names_v2.txt 1d0 \u003c 8a8,10 \u003e Molina \u003e diff -y: side by side comparison\nWe can use diff -y or sdiff to compare two files and display the matched and unmatched records side-by-side. Unlike the default diff, the -y option displays both matched and unmatched records. If we do not want to see the matched records, we can use the --suppress-matched-lines option along with -y.\n$ diff -y names_v1.txt names_v2.txt | Huang HUANG | Sherman Sherman | Gordon Gordon | Gomez GOMEZ | Cook Cook | Daugherty Daugherty | Macias MACIAS | \u003e Molina \u003e # suppress trailing blanks and case-insensitive compare # discard matched records # one blank records in each file and one extra record $ diff -b -y -i --suppress-common-lines names_v1.txt names_v2.txt \u003c \u003e \u003e Molina comm: compare 2 sorted files side-by-side The comm command is a good choice to compare files with short records like name lists. It compares the files and displays a 3 column output; column 1 contains records unique to FILE 1, column 2 is unique records from FILE 2 and column 3 has the common records between 2 files.\n   Option Description     -1 suppress unique records from FILE 1   -2 suppress unique records from FILE 2   -3 suppress common records from FILE 1 and FILE 2   --total print summary; unique records count file 1 and file 2, common records count   --output-delim=CHAR override output delimiter, TAB is the default value    Examples:\nLet us tweak the names_v1.txt and names_v2.txt files a bit by keeping 3 common records and 2 unique records each in sorted order.\n$ cat names_v1.txt Cook Daugherty Gomez Gordon Huang Macias $ cat names_v2.txt Gomez Gordon Huang Macias Molina Sherman comm: basic comparison\n$ comm names_v1.txt names_v2.txt Cook Daugherty Gomez Gordon Huang Macias Molina Sherman comm: suppress columns\n# show only unique records from FILE 1 $ comm -2 -3 names_v1.txt names_v2.txt Cook Daugherty # show only unique records from FILE 2 $ comm -1 -3 names_v1.txt names_v2.txt Molina Sherman # show common records between FILE 1 and FILE 2 $ comm -1 -2 names_v1.txt names_v2.txt Gomez Gordon Huang Macias comm --total: display comparison summary\nEven if we suppress, the summary line always shows the count of unique records from file 1, file2 and the common records count.\n$ comm --total names_v1.txt names_v2.txt Cook Daugherty Gomez Gordon Huang Macias Molina Sherman 2 2 4 total # show only unique records from FILE 1 and summary $ comm --total -2 -3 names_v1.txt names_v2.txt Cook Daugherty 2 2 4 total comm: display only summary\n$ comm --total -1 -2 -3 names_v1.txt names_v2.txt 2 2 4 total Override Output delimiter\n# no trailing commas as delimiter after columns with # unique records only $ comm --output-delimiter=, names_v1.txt names_v2.txt Cook Daugherty ,,Gomez ,,Gordon ,,Huang ,,Macias ,Molina ,Sherman Get unique records from both files\nThe comm command creates a 3 column output with TAB as column delimiter. If we redirect the output of comm into tr to delete the TAB character, then all 3 columns will become one column. To get the unique rows, we can further sort and uniq the output.\nIn order to demonstrate this, I have added some duplicate rows in both files\n# common and unique rows merged as one column (with duplicates) $ comm names_v1.txt names_v2.txt | tr -d '\\t' Cook Daugherty Gomez Gordon Gordon Gordon Huang Macias Macias Macias Molina Sherman # sort the output and remove duplicates # instead of uniq we can use 'sort' with -u'  $ comm names_v1.txt names_v2.txt | tr -d '\\t' | sort | uniq Cook Daugherty Gomez Gordon Huang Macias Molina Sherman Comparison using file checksum We have discussed diff, comm and cmp commands that can be used for comparing files. At times, we are just interested in whether the files are identical or not without worrying about the actual differences. This can be accomplished by checking the return code by executing echo $? right after running the comparison command where return code 0 means identical and 1 means differences found.\nAnother way is to get the checksum, also known as digest or hash value of the files. Same checksum value means the files are identical. The commands cksum, md5sum and shasum can be used to get the checksum values. Each command uses different hashing algorithm to compute the checksum values with cksum being the oldest and shasum being the latest.\nThe cksum displays checksum, file size and file name. The md5sum and shasum just displays the checksum and file name.\nLet us compare the names_v[12].txt files. We will make a copy of v2 as v3 for identical comparison.\nExamples:\n$ cp -v names_v2.txt names_v3.txt 'names_v2.txt' -\u003e 'names_v3.txt' #using chksum: v2 and v3 has same checksum  $ cksum names_v1.txt names_v2.txt names_v3.txt 1628559629 108 names_v1.txt 3965335266 96 names_v2.txt 3965335266 96 names_v3.txt # same as cksum; v2 and v3 has same checksum # md5sum is more accurate than cksum $ md5sum names_v* 9dbff2393937f0724cd532f83756955b names_v1.txt 9cbf9656ccd27ca37b5a3be7b5b4de71 names_v2.txt 9cbf9656ccd27ca37b5a3be7b5b4de71 names_v3.txt # shasum is more accurate than md5sum. # we can even create longer digest using options # v2 and v3 has same cksum $ shasum names_v* d567ba96fc3aa36c28708f9c8075cdf607bd3ea8 names_v1.txt a44bf3187d86a30e5273e939035d9d916b10568f names_v2.txt a44bf3187d86a30e5273e939035d9d916b10568f names_v3.txt shuf: shuffle records / arguments The shuf command can be used to randomize the records from a file or the arguments passed to the command. This comes handy if we need to pick random records or words (arguments delimited by spaces). The shuffled records will be written to stdout. The options allow us to limit the number of records, duplicate records or write the output to a file.\n   Output Description     -e treat each arg as a input record   -n N limit the number of output records   -r repeat records (duplicate), use along with -n   -o FILE write to FILE    Examples:\nshuf -e ARG(s): Randomize inputs passed as arguments\n$ shuf -e abcd efgh ijkl mnop qrstu vwxyz ijkl abcd efgh vwxyz mnop qrstu shuf -n N: Limit output records\n$ shuf -n3 -e abcd efgh ijkl mnop qrstu vwxyz qrstu ijkl efgh shuf -n N -r: repeat input records and limit records\n# duplicates: rec=1 and 4, 6 and 7, 5 and 8 $ shuf -n10 -r -e abcd efgh ijkl mnop qrstu vwxyz | nl 1 mnop 2 qrstu 3 abcd 4 mnop 5 vwxyz 6 ijkl 7 ijkl 8 vwxyz 9 efgh 10 qrstu shuf -o FILE: shuffle and write to file\n# displays nothing, use `cat FILE` to inspect output $ shuf -n3 -o shuffle.txt -e abcd efgh ijkl mnop qrstu vwxyz $ cat shuffle.txt mnop abcd ijkl shuf: randomize records from a file\nLet us add line numbers to names_v1.txt using the nl command and process it thru the shuf command.\n DIY: Try other options discussed above with shuf and FILE\n $ nl names_v1.txt \u003e names.txt # original file with record numbers $ cat names.txt 1 Cook 2 Daugherty 3 Gomez 4 Gordon 5 Huang 6 Macias # shuffled records $ shuf names.txt 1 Cook 2 Daugherty 3 Gomez 4 Gordon 5 Huang 6 Macias Use Case Fake Data Creation Script\n Install the faker module from pip before running this script. This document does not support copy-paste really well. you may have to type the command or create a sample file yourself\n from faker import Faker import random f = Faker() subjects = ('MATH', 'SCIE', 'SOCS') cf = open('student.csv', 'w') ff = open('student.txt', 'w') print(\"Id,LastName,FirstName,DOB,grade,subject,score,En\",file=cf) for i in range(1, 101): stu_id = f\"S{i:05}\" lname = f.last_name() fname = f.first_name() birth_year = random.randint(2009, 2013) birth_ddmmm = f.date(\"%d-%b\") dob = f\"{birth_ddmmm}-{birth_year}\" grade = f\"{(2021 - birth_year - 5):02}\" for subj in subjects: scr = random.randrange(51, 100) print(f\"{stu_id} {lname:10} {fname:10} {dob} {subj} {grade} {scr:3} Z\", file=ff) print(stu_id, lname, fname, dob, subj, grade, scr, \"Z\", sep=\",\", file=cf) ff.close() cf.close() ",
    "description": "",
    "tags": null,
    "title": "1.8: Data Manipulation",
    "uri": "/part-1/p1-ch7/"
  },
  {
    "content": "Chapter 9 Introduction So far, we ran commands one after another in order to accomplish some tasks. We split our task into sub-tasks in such a way that each sub-task could be solved by one command. The commands usually run fast with small input size. However we need to be active to type one command after other and our presence in front of the machine is needed.\nWhen we start using commands to process large files, one command may run for a longer duration and we have to wait for the command to complete before running another command. This can be frustrating. Fortunately, Linux provides us several options to submit commands together and let Linux takes care of executing the commands in the order it was entered.\nRunning multiple commands using | In the previous chapters, we have learnt how to use the redirection using the pipe operator to run related commands by passing the output of one command as input to the next command. This works only for commands that are related and one command depends on the previous command for input and we are interested in the output of the last command alone.\nOther ways to run multiple commands Here are some of the ways we can submit multiple unrelated command sequentially and let Linux takes care of executing it one-by-one.\n commands separated by semi-colon cmd1; cmd2; cmd3 commands separated by semi-colon and enclosed within curly braces { cmd1; cmd2; cmd3; } commands separated by semi-colon and enclosed within parenthesis ( cmd1; cmd2; cmd3; ) Conditional executing using \u0026\u0026 and || - cmd1 \u0026\u0026 cmd2, cmd1 || cmd2 or cmd1 \u0026\u0026 cmd2 || cmd3 Capturing command’s output in a variable using the backticks - `cmd` or VAR=$( cmd1 | cmd2 ) syntax Passing command’s output as an argument cmd1 \u003c(cmd2) \u003c(cmd3) Run one or more commands several times using a for loop from the command line. Run previously executed commands with or without changes using shortcuts associated with the history command Run previous command by replacing arguments using fc -s \"OLD=NEW\" command  Running Multiple Commands: so far… Here are two examples; one uses the pipe to run related commands in one go. The second example is to run series of unrelated commands one after another manually.\nExample 1: Extract name and scores and transform the data\nWe have a student delimited file that contains test scores. We need to extract the student id, last and first names, grade and score; convert the names to uppercase and sort the data by grade, score and last and first names where grade and names will be sorted ascending and the score in descending order.\nSample file $ cat student_file.txt S0001,Smith,John,10-JAN-2004,04,372,Z S0002,Smith,Jane,21-FEB-2004,04,385,Z S0003,Smith,John,14-OCT-2003,04,425,Z S0004,Smyth,Dan,25-DEC-2002,05,499,Z S0004,Lowes,Ben,12-MAY-2001,05,499,Z S0005,Cook,Lisa,28-SEP-2011,05,83,Z S0006,Daugherty,Joshua,05-APR-2011,05,94,Z S0007,Macias,Emma,21-SEP-2009,07,79,Z Formatted output using | $ cut -d, -f1,2,3,5,6 student_file.txt | tr 'a-z' 'A-Z' | sort -t, -k4,4 -k5,5nr -k2,2 -k3,3 S0003,SMITH,JOHN,04,425 S0002,SMITH,JANE,04,385 S0001,SMITH,JOHN,04,372 S0004,LOWES,BEN,05,499 S0004,SMYTH,DAN,05,499 S0005,COOK,LISA,05,83 S0006,DAUGHERTY,JOSHUA,05,94 S0007,MACIAS,EMMA,07,79 Example 2: display dates before and after sleep N\nLet us say, we want to verify the time taken by sleep N command is closer to N seconds. We can run the date command before and after sleep and check. However, we need to type the commands quickly and execute to get an accurate result.\nI took 3 extra seconds to run the sleep and the second date command.\n$ date Tue Aug 17 14:32:15 IST 2021 $ sleep 5 $ date Tue Aug 17 14:32:23 IST 2021 Running Commands Together The pipe operator works well to run related commands. In this section let us look at other ways to run multiple commands; dependent on each other or just a set of commands to run one after another automatically.\nUsing the semicolon ; operator The semicolon ; operator acts like an implicit newline as if the Enter key is pressed. We can type a series of commands separated by semicolon and when we press the Enter key, the commands will execute in the order in which they appear in the command-line.\nLet us rewrite the sleep and date command sequence from the previous section using the ; operator.\n# run commands one after another $ date Tue Aug 17 15:48:48 IST 2021 $ sleep 5 $ date Tue Aug 17 15:48:55 IST 2021 # run commands in sequence using ';' $ date; sleep 5; date Tue Aug 17 15:49:52 IST 2021 Tue Aug 17 15:49:58 IST 2021 Command Grouping: {} and ; operator Running commands sequentially using ; operator serves us well if we just need to run these commands. In case we need to capture the output in a file using redirection and if we use IO redirection at the end then only the last command’s output will be captured. For example, in the below example, the output of first date command is displayed on the screen and the last command’s output is redirected.\n$ date; sleep 5; date \u003e date.txt Tue Aug 17 15:52:41 IST 2021 $ cat date.txt Tue Aug 17 15:52:46 IST 2021 We can use group the commands by enclosing the command sequence inside the {} operator. This will ensure that all the commands enclosed within the braces are treated as a single entity and redirecting using the {} \u003e FILE syntax will redirect the output from all the commands into the FILE.\n$ { date; sleep 5; date; } \u003e date.txt $ cat date.txt Tue Aug 17 15:55:40 IST 2021 Tue Aug 17 15:55:45 IST 2021 Another Example Let us add header to the student_file.txt we have used earlier.\n$ cat student_file.txt S0001,Smith,John,10-JAN-2004,04,372,Z S0002,Smith,Jane,21-FEB-2004,04,385,Z $ { echo \"StudentId,LastName,FirstName,DateOfBirth,Grade,Score,End\"; cat student_file.txt; } \u003e student_file_with_header.txt $ cat student_file_with_header.txt StudentId,LastName,FirstName,DateOfBirth,Grade,Score,End S0001,Smith,John,10-JAN-2004,04,372,Z S0002,Smith,Jane,21-FEB-2004,04,385,Z Points to Remember  Since the {} is an operator in bash, we need to leave a blank between the brace and the command Each command should be terminated with a semicolon including the last command. The commands will be executed within the same shell so all the environmental and user-defined variables will be available and can be manipulated within the {}. More on variables later…  Shell Variables and {} As mentioned above, the shell variables updated within the {} grouping will be visible even after all the commands within {} complete execution. If we want to have local scope of variable assignment, we can use the parenthesis () grouping instead.\n$ x=10; echo \"OUT: x is $x\"; { echo \"IN : x is $x\";x=20; echo \"IN : x now is $x\"; }; echo \"OUT: x is $x\" OUT: x is 10 IN : x is 10 IN : x now is 20 OUT: x is 20 Command Grouping: () and ; operator Grouping the commands using the parenthesis is similar to the braces in terms of redirection. Both grouping options treats the entire command list enclosed in between as single entity thus complete output is redirected into same output file.\nThere are couple of differences between the way {} and () works. We saw that {} runs all the commands in the same shell. The () grouping runs the command list in a new shell environment called sub-shell. Since all the commands run inside a new shell, any variable created or assigned inside the () will not be available once the commands complete execution.\nThe () does not need space-delimiter and the last command does not have to be terminated by the ;. Here is the same example from previous section. There is no space between () and the commands and there is no ; after the last command. However, adding spaces and ; at the end of the last command adds readability\n$ (date;sleep 5; date) \u003e date.txt $ cat date.txt Tue Aug 17 16:09:23 IST 2021 Tue Aug 17 16:09:28 IST 2021 # no issues adding spaces between '()' and commands # or semicolon at the end $ ( date; sleep 5; date; ) \u003e date.txt $ cat date.txt Tue Aug 17 16:10:57 IST 2021 Tue Aug 17 16:11:02 IST 2021 Shell Variables and () Commands that runs within () use a separate shell (sub-shell) to run the commands. If any variable assignment or new variable declaration happens within the (), these changes will not be available once the sub-shell completes executing the commands. If we need to persist the changes, we need to use the braces {} grouping instead of parenthesis () grouping.\n more on variables later when we discuss shell scripting\n In the below example, we have shell variable x set to 10 and displayed outside the (). The variable x is displayed again within () before and after updating the variable. Once the sub-shell completes execution, the value of x is lost and original value will be displayed.\n$ x=10; echo \"OUT: x is $x\"; (echo \"IN : x is $x\";x=20; echo \"IN : x now is $x\"); echo \"OUT: x is $x\" OUT: x is 10 IN : x is 10 IN : x now is 20 OUT: x is 10 Conditional Execution using \u0026\u0026 and || Sometimes, we may need to run a command based on the outcome of the previous command. This is known as conditional execution which is different from the sequential execution examples we have seen so far using ;, {} and ().\nWe can use the \u0026\u0026 - AND operator to run the second command ONLY if the first command is successful. That is the first command returns a return code 0 (echo $?). The || - OR command, on the contrary executes the second command ONLY if the first command is unsuccessful (RC \u003e 0). We can use the combination of \u0026\u0026 and || to construct a longer command sequence that can be run conditionally.\nLots of time, we create a directory and then change to it immediately after. Instead of running the two commands separately, we can combine the mkdir and cd with \u0026\u0026 operator so that if mkdir is successful then run the cd next. For demo, I have added the echo command that will run ONLY if the cd is successful.\n$ mkdir temp \u0026\u0026 cd temp \u0026\u0026 echo \"created and changed to 'temp' directory\" created and changed to 'temp' directory Sometimes we may want to customize the error message provided on commands. We cause use the || operator to display a custom error message if a command fails. This solution works well on commands that also provide an option to suppress the error message using option. The cmp command to compare files is one such example. It displays nothing when both files match, the command does not display anything and a message if the files are different. The return code is set to 1 if the files are different. We can suppress the default error message using the -s option.\n$ echo \"A\" \u003e file_1.txt $ echo \"a\" \u003e file_2.txt $ cmp file_1.txt file_2.txt file_1.txt file_2.txt differ: char 1, line 1 $ echo $? 1 $ cmp -s file_1.txt file_2.txt || echo \"Both files differ, removing files...\" \u0026\u0026 rm -v file_[12].txt Both files differ, removing files... file_1.txt file_2.txt Capturing Command Output in a Shell Variable Sometimes, we may neither want the output of a command to be displayed nor redirected to a file. We just need to capture the output in a shell variable and display it later using the echo or printf command.\nThere are two ways to capture the output of command(s) in a variable; using the backticks (`) which is the old way and using the $( cmd ) syntax which is the preferred way.\n The backtick that looks like single-quote can be found under the ESC key. The ~ and backtick shares the same key.\n In the previous section, we have concatenated the header of a CSV file using echo and cat commands and the { cmd; cmd; } \u003e FILE syntax. Let us add the record count at the end of the file like the output of RDBMS table export as CSV.\nWe can capture the record count of wc -l in a variable and later use it in a echo command to construct a string and display the count.\n$ wc -l student_file.txt 2 student_file.txt $ wc -l student_file.txt | cut -d' ' -f1 2 $ echo student_file.txt student_file.txt # capture file name in variable called 'file' $ file=$(echo student_file.txt) $ count=$(wc -l student_file.txt | cut -d' ' -f1) # construct the string using variable and literals $ echo \"$filehas $countrecord(s)\" student_file.txt has 2 record(s) We can use ` instead of the $( ) syntax too. Using backticks was the old way of capturing command output. The $( ) syntax is preferred since many may confuse backtick with single-quotes.\n$ file=`echo student_file.txt` $ count=`wc -l student_file.txt | cut -d' ' -f1` $ echo \"$filehas $countrecord(s)\" student_file.txt has 2 record(s) Let us put the above together to add a footer to a delimited file\n# set variables: header and file name $ hdr=\"StudentId,LastName,FirstName,DateOfBirth,Grade,Score,End\" $ file=\"student_file.txt\" # use var=$(cmd) and { cmd; cmd; } $ { echo $hdr; cat $file; count=$(wc -l $file | cut -d' ' -f1); \\ \u003e echo -e \"\\n$filehas $countrecord(s)\\n\"; } \u003e student_file_with_header.txt # display output $ cat student_file_with_header.txt StudentId,LastName,FirstName,DateOfBirth,Grade,Score,End S0001,Smith,John,10-JAN-2004,04,372,Z S0002,Smith,Jane,21-FEB-2004,04,385,Z S0003,Smith,John,14-OCT-2003,04,425,Z S0004,Lowes,Ben,12-MAY-2001,05,499,Z S0005,Cook,Lisa,28-SEP-2011,05,83,Z student_file.txt has 5 record(s) Passing Command Output as Argument using Sub-Shell Sometimes, we might want to pass part of a file or files as argument to another command or pass the output of multiple commands as argument to another command. We have two options to handle situations like this\n Run the commands one-by-one and create temporary files first and pass the files to the command in question Run each command using the \u003c( cmds ) syntax and code one or more \u003c() as argument to the command in question  The first option is kind of self-explanatory. Let us say, we want to compare the last names from two CSV files where the last name is the second field. We can do the following\n cut -d',' -f2 FILE1 | sort \u003e LNAME1.txt cut -d',' -f2 FILE2 | sort \u003e LNAME2.txt comm LNAME1.txt LNAME2.txt \u003e DIFF.TXT rm -v LNAME*  The above solution works fine. It just we need to perform 3 or 4 steps to get the required output.\nThe second option accomplishes the same result in just one step.\n$ comm \u003c(cut -d',' -f2 FILE1 | sort \u003e LNAME1.txt) \u003c(cut -d',' -f2 FILE2 | sort \u003e LNAME2.txt) \u003e DIFF.TXT The \u003c() syntax has two components that we are already familiar of. \u003c - input redirection and () - running multiple commands together. Since () runs as separate process, the output is passed in a temporary file to the command in question. The temp files will be deleted automatically once the process is done.\nExample: Option 1 $ cut -d, -f2 sample_01.txt | sort \u003e temp_01.txt $ cut -d, -f2 sample_02.txt | sort \u003e temp_02.txt $ head temp_0* ==\u003e temp_01.txt \u003c== Daugherty Gomez Gordon Huang Sherman ==\u003e temp_02.txt \u003c== Gomez Gordon Huang Moore Sherman # 4 unique names in each file and 1 common names $ comm temp_01.txt temp_02.txt Daugherty Gomez Gordon Huang Moore Sherman $ rm temp_0[12].txt Example: Option 2 $ comm \u003c(cut -d, -f2 sample_01.txt | sort) \u003c(cut -d, -f2 sample_02.txt | sort) Daugherty Gomez Gordon Huang Moore Sherman Running Commands Repeatedly using a for loop Though we will discuss loops in detail as part of shell scripting, let us quickly look at the for loop syntax that can be used in the command line to run one or more commands multiple time.\nsyntax of for loop\n The for loops thru a set of items with each iteration assigns one element from the set of items The items can be a space-separated sentence, command’s output or brace expansion’s output {1..10}\n for VAR in ITEMS; do cmd1; cmd2; done for VAR in ITEMS; do cmd1; cmd2; done Example:\n$ for i in {3..1}; do echo Countdown $i...; done ; echo Liftoff Countdown 3... Countdown 2... Countdown 1... Liftoff We have a set of files with sample_ prefix. Let us run wc -l command for each file using the for loop and print FILE has COUNT record(s).\n$ for FILE in sample_*; do count=$( wc -l $FILE | cut -d' ' -f1 ); echo \"$FILEhas $countrecord(s)\"; done sample_01.txt has 6 record(s) sample_02.txt has 6 record(s) sample_03.txt has 2 record(s) sample_04.txt has 4 record(s) sample_05.txt has 6 record(s) # verify $ wc -l sample_0[1-5].txt 6 sample_01.txt 6 sample_02.txt 2 sample_03.txt 4 sample_04.txt 6 sample_05.txt Run old commands from history The history command displays previously executed commands. This is helpful for novice learners as a reference. Linux keeps the last 500 commands in a hidden file ~/.bash_history in the home directory and the history command uses this file to display the commands with serial number in front of it.\n$ history | head -5 80 wc -l large_file.txt 81 ls -lh large_file.txt 82 clear 83 ls 84 jobs There is another use of the history command. We can run one of the old commands using some shortcuts.\n These are few of the simple shortcuts we can use to execute or retrieve past commands from the history. For more information, look for articles / documentations related to the history command\n    Shortcut Description     !! run previous command again   !N run command with serial number N   !-N run the Nth command from the end   !!:p just print the previous command without executing it.    we can use up arrow and make some modification and run   !N:p print command N   !-N:p print command N counting backward    $ date Thu 26 Aug 2021 02:13:48 PM UTC # runs previous: date command again $ !! date Thu 26 Aug 2021 02:13:52 PM UTC $ !!:p date $ history | tree -5 524 history 525 vi ~/.bash_profile 526 cat ~/.bash_profile 527 wc -l ~/.bash_profile 528 history $ !527:p wc -l ~/.bash_profile # press up arrow and change the last printed command $ wc -l ~/.bash_history 500 /home/mktutes/.bash_history $ history | tail -5 528 history 529 wc -l ~/.bash_profile 530 wc -l ~/.bash_history 531 history 532 history | tail -5 $ !-4 wc -l ~/.bash_profile 3 /home/mktutes/.bash_profile Run previous commands and optionally replace args The fc - fix command can be used to modify the previous command by performing simple substitutions.\n$ touch demo_{01..05}.csv ls demo_01.csv demo_03.csv demo_05.csv demo_02.csv demo_04.csv # replace demo with sample, csv with txt  # and run the last command $ fc -s \"demo=sample\" \"csv=txt\" touch sample_{01..05}.txt $ ls demo_01.csv demo_04.csv sample_02.txt sample_05.txt demo_02.csv demo_05.csv sample_03.txt demo_03.csv sample_01.txt sample_04.txt References  Grouping Commands: GNU Bash Manual  ",
    "description": "",
    "tags": null,
    "title": "1.9: Running Commands",
    "uri": "/part-1/p1-ch8/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Categories",
    "uri": "/categories/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tags",
    "uri": "/tags/"
  }
]
